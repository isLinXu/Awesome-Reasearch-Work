# Language-Models

| Model / Methods      | Title                                                                                                                                                       | Paper Link                                                                                                                                                                                                                                        | Code Link                                                                                                                                                                                                                                                                               | Published | Keywords         | Venue                                                                                                 |
| -------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------- | ---------------- | ----------------------------------------------------------------------------------------------------- |
| ALBERT               | ALBERT: A Lite BERT for Self-supervised Learning of Language Representations                                                                                | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1909.11942)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/ALBERT)![Star](https://img.shields.io/github/stars/google-research/ALBERT.svg?style=social&label=Star)                                                                       | 2019      | google-research  |                                                                                                       |
| BART                 | BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension                                           | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1910.13461)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/fairseq/tree/main/examples/bart)![Star](https://img.shields.io/github/stars/facebookresearch/fairseq.svg?style=social&label=Star)                                           | 2019      | facebookresearch |                                                                                                       |
| BARThez              | BARThez: a Skilled Pretrained French Sequence-to-Sequence Model                                                                                             | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2010.12321)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/moussaKam/BARThez)![Star](https://img.shields.io/github/stars/moussaKam/BARThez.svg?style=social&label=Star)                                                                                 | 2020      | moussaKam        |                                                                                                       |
| BARTpho              | BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese                                                                                             | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2109.09701)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/VinAIResearch/BARTpho)![Star](https://img.shields.io/github/stars/VinAIResearch/BARTpho.svg?style=social&label=Star)                                                                         | 2022      | VinAIResearch    | INTERSPEECH 2022                                                                                      |
| BERT                 | BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding                                                                            | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1810.04805)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/bert)![Star](https://img.shields.io/github/stars/google-research/bert.svg?style=social&label=Star)                                                                           | 2018      |                  |                                                                                                       |
| BertGeneration       | Leveraging Pre-trained Checkpoints for Sequence Generation Tasks                                                                                            | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1907.12461)                                                                                                                                       | ![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)                                                                                                                                                                                                                   | 2019      |                  |                                                                                                       |
| BERTweet             | BERTweet: A pre-trained language model for English Tweets                                                                                                   | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://www.aclweb.org/anthology/2020.emnlp-demos.2.pdf)                                                                                                                | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/VinAIResearch/BERTweet)![Star](https://img.shields.io/github/stars/VinAIResearch/BERTweet.svg?style=social&label=Star)                                                                       | 2020      |                  | EMNLP-2020                                                                                            |
| BigBird              | Big Bird: Transformers for Longer Sequences                                                                                                                 | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2007.14062)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/bigbird)![Star](https://img.shields.io/github/stars/google-research/bigbird.svg?style=social&label=Star)                                                                     | 2020      |                  | [NeurIPS 2020](https://papers.nips.cc/paper/2020/hash/c8512d142a2d849725f31a9a7a361ab9-Abstract.html) |
| BioGPT               | BioGPT: generative pre-trained transformer for biomedical text generation and mining                                                                        | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://academic.oup.com/bib/advance-article/doi/10.1093/bib/bbac409/6713511?guestAccessKey=a66d9b5d-4f83-4017-bb52-405815c907b9)                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/microsoft/BioGPT)![Star](https://img.shields.io/github/stars/microsoft/BioGPT.svg?style=social&label=Star)                                                                                   | 2022      |                  |                                                                                                       |
| Blenderbot           | Recipes for building an open-domain chatbot                                                                                                                 | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/pdf/2004.13637.pdf)                                                                                                                                   | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/ParlAI)![Star](https://img.shields.io/github/stars/facebookresearch/ParlAI.svg?style=social&label=Star)                                                                     | 2020      |                  |                                                                                                       |
| BLOOM                | Introducing The World’s Largest Open Multilingual Language Model: BLOOM                                                                                     | [![Paper](https://img.shields.io/badge/Blog-ydd7e6?style=for-the-badge)](https://bigscience.huggingface.co/blog/bloom)                                                                                                                            | ![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)                                                                                                                                                                                                                   | 2022      |                  |                                                                                                       |
| BORT                 | Optimal Subarchitecture Extraction for BERT                                                                                                                 | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2010.10499)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/alexa/bort)![Star](https://img.shields.io/github/stars/alexa/bort.svg?style=social&label=Star)                                                                                               | 2020      |                  |                                                                                                       |
| ByT5                 | ByT5: Towards a token-free future with pre-trained byte-to-byte models                                                                                      | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2105.13626)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/byt5)![Star](https://img.shields.io/github/stars/google-research/byt5.svg?style=social&label=Star)                                                                           | 2021      |                  |                                                                                                       |
| CamemBERT            | CamemBERT: a Tasty French Language Model                                                                                                                    | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1911.03894)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://camembert-model.fr/)                                                                                                                                                                                    | 2019      |                  |                                                                                                       |
| CANINE               | CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation                                                                     | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.06874)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/language/tree/master/language/canine)![Star](https://img.shields.io/github/stars/google-research/language.svg?style=social&label=Star)                                       | 2021      | Google-research  |                                                                                                       |
| CodeGen              | A Conversational Paradigm for Program Synthesis                                                                                                             | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2203.13474)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/salesforce/codegen)![Star](https://img.shields.io/github/stars/salesforce/codegen.svg?style=social&label=Star)                                                                               | 2022      | salesforce       |                                                                                                       |
| CodeLlama            | Code Llama: Open Foundation Models for Code                                                                                                                 | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/)                                                                                  | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/llama)![Star](https://img.shields.io/github/stars/facebookresearch/llama.svg?style=social&label=Star)                                                                       | 2023      |                  |                                                                                                       |
| Cohere               | Command-R: Retrieval Augmented Generation at Production Scale                                                                                               | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://cohere.com/blog/command-r)                                                                                                                                      | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/EleutherAI/gpt-neox)![Star](https://img.shields.io/github/stars/facebookresearch/llama.svg?style=social&label=Star)                                                                          | 2024      |                  |                                                                                                       |
| ConvBERT             | ConvBERT: Improving BERT with Span-based Dynamic Convolution                                                                                                | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2008.02496)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/TsinghuaAI/CPM-Generate)![Star](https://img.shields.io/github/stars/yitu-opensource/ConvBert.svg?style=social&label=Star)                                                                    | 2020      |                  |                                                                                                       |
| CPM                  | CPM: A Large-scale Generative Chinese Pre-trained Language Model                                                                                            | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2012.00413)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/TsinghuaAI/CPM-Generate)![Star](https://img.shields.io/github/stars/TsinghuaAI/CPM-Generate.svg?style=social&label=Star)                                                                     | 2020      |                  |                                                                                                       |
| CPMAnt               | CPM-Ant is an open-source Chinese pre-trained language model (PLM) with 10B parameters.                                                                     | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://github.com/OpenBMB/CPM-Live/tree/cpm-ant/cpm-live)                                                                                                              | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/OpenBMB/CPM-Live/tree/cpm-ant/cpm-live)![Star](https://img.shields.io/github/stars/OpenBMB/CPM-Live.svg?style=social&label=Star)                                                             | 2020      |                  |                                                                                                       |
| CTRL                 | CTRL: A Conditional Transformer Language Model for Controllable Generation                                                                                  | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1909.05858)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/salesforce/ctrl)![Star](https://img.shields.io/github/stars/salesforce/ctrl.svg?style=social&label=Star)                                                                                     | 2019      |                  |                                                                                                       |
| DBRX                 | DBRX is a [transformer-based](https://www.isattentionallyouneed.com/) decoder-only large language model (LLM) that was trained using next-token prediction. | [![Paper](https://img.shields.io/badge/Blog-ydd7e6?style=for-the-badge)](https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm)                                                                                                 | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/databricks/dbrx-instruct)![Star](https://img.shields.io/github/stars/databricks/dbrx-instruct.svg?style=social&label=Star)                                                                   | 2024      |                  |                                                                                                       |
| DeBERTa              | DeBERTa：Decoding-enhanced BERT with Disentangled Attention                                                                                                  | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2006.03654)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/microsoft/DeBERTa)![Star](https://img.shields.io/github/stars/microsoft/DeBERTa.svg?style=social&label=Star)                                                                                 | 2020      |                  |                                                                                                       |
| DeBERTa-v2           | DeBERTa：Decoding-enhanced BERT with Disentangled Attention                                                                                                  | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2006.03654)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/microsoft/DeBERTa)![Star](https://img.shields.io/github/stars/microsoft/DeBERTa.svg?style=social&label=Star)                                                                                 | 2021      |                  |                                                                                                       |
| DialoGPT             | DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation                                                                        | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1911.00536)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/microsoft/DialoGPT)![Star](https://img.shields.io/github/stars/microsoft/DialoGPT.svg?style=social&label=Star)                                                                               | 2019      |                  |                                                                                                       |
| DistilBERT           | DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter                                                                               | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1910.01108)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation)                                                                                                                  | 2019      |                  |                                                                                                       |
| DPR                  | Dense Passage Retrieval for Open-Domain Question Answering                                                                                                  | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2004.04906)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/DPR)![Star](https://img.shields.io/github/stars/facebookresearch/DPR.svg?style=social&label=Star)                                                                           | 2020      |                  |                                                                                                       |
| ELECTRA              | ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators                                                                                | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://openreview.net/pdf?id=r1xMH1BtvB)                                                                                                                               | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/electra)![Star](https://img.shields.io/github/stars/google-research/electra.svg?style=social&label=Star)                                                                     | 2020      |                  |                                                                                                       |
| ERNIE 1.0            | ERNIE: Enhanced Representation through Knowledge Integration                                                                                                | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1904.09223)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/PaddlePaddle/ERNIE)![Star](https://img.shields.io/github/stars/PaddlePaddle/ERNIE.svg?style=social&label=Star)                                                                               | 2019      |                  |                                                                                                       |
| ERNIE 2.0            | ERNIE 2.0: A Continual Pre-Training Framework for Language Understanding                                                                                    | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://ojs.aaai.org/index.php/AAAI/article/view/6428)                                                                                                                  | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/PaddlePaddle/ERNIE)![Star](https://img.shields.io/github/stars/PaddlePaddle/ERNIE.svg?style=social&label=Star)                                                                               | 2020      |                  | AAAI 2020                                                                                             |
| ERNIE 3.0            | ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language Understanding and Generation                                                            | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2107.02137)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/PaddlePaddle/ERNIE)![Star](https://img.shields.io/github/stars/PaddlePaddle/ERNIE.svg?style=social&label=Star)                                                                               | 2021      |                  |                                                                                                       |
| ERNIE-Gram           | ERNIE-Gram: Pre-Training with Explicitly N-Gram Masked Language Modeling for Natural Language Understanding                                                 | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2010.12148)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/PaddlePaddle/ERNIE)![Star](https://img.shields.io/github/stars/PaddlePaddle/ERNIE.svg?style=social&label=Star)                                                                               | 2020      |                  |                                                                                                       |
| ERNIE-health         | Building Chinese Biomedical Language Models via Multi-Level Text Discrimination                                                                             | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2110.07244)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/PaddlePaddle/ERNIE)![Star](https://img.shields.io/github/stars/PaddlePaddle/ERNIE.svg?style=social&label=Star)                                                                               | 2022      |                  |                                                                                                       |
| ErnieM               | ERNIE-M: Enhanced Multilingual Representation by Aligning Cross-lingual Semantics with Monolingual Corpora                                                  | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2012.15674)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/PaddlePaddle/ERNIE)![Star](https://img.shields.io/github/stars/PaddlePaddle/ERNIE.svg?style=social&label=Star)                                                                               | 2020      |                  |                                                                                                       |
| ESM                  | Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences                                                | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://www.pnas.org/content/118/15/e2016239118)                                                                                                                        | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/esm)![Star](https://img.shields.io/github/stars/facebookresearch/esm.svg?style=social&label=Star)                                                                           | 2022      |                  |                                                                                                       |
| Falcon               | The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only                                                       | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2306.01116)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/huggingface/transformers/tree/main/src/transformers/models/falcon)![Star](https://img.shields.io/github/stars/huggingface/transformers.svg?style=social&label=Star)                          | 2023      |                  |                                                                                                       |
| FastSpeech2Conformer | Recent Developments On Espnet Toolkit Boosted By Conformer                                                                                                  | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2010.13956)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/espnet/espnet)![Star](https://img.shields.io/github/stars/espnet/espnet.svg?style=social&label=Star)                                                                                         | 2020      |                  |                                                                                                       |
| FLAN-T5              | Scaling Instruction-Finetuned Language Models                                                                                                               | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/pdf/2210.11416.pdf)                                                                                                                                   | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/t5x/blob/main/docs/models.md#flan-t5-checkpoints)![Star](https://img.shields.io/github/stars/google-research/t5x.svg?style=social&label=Star)                                | 2022      |                  |                                                                                                       |
| FLAN-UL2             | UL2: Unifying Language Learning Paradigms                                                                                                                   | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/pdf/2210.11416.pdf)                                                                                                                                   | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/t5x/blob/main/docs/models.md#flan-t5-checkpoints)![Star](https://img.shields.io/github/stars/google-research/t5x.svg?style=social&label=Star)                                | 2022      |                  |                                                                                                       |
| FlauBERT             | FlauBERT：Unsupervised Language Model Pre-training for French                                                                                                | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1912.05372)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/getalp/Flaubert)![Star](https://img.shields.io/github/stars/getalp/Flaubert.svg?style=social&label=Star)                                                                                     | 2019      |                  |                                                                                                       |
| FNet                 | FNet: Mixing Tokens with Fourier Transforms                                                                                                                 | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2105.03824)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/google-research/tree/master/f_net)![Star](https://img.shields.io/github/stars/google-research/google-research.svg?style=social&label=Star)                                   | 2021      |                  |                                                                                                       |
| FSMT                 | Facebook FAIR’s WMT19 News Translation Task Submission                                                                                                      | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1907.06616)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/pytorch/fairseq/tree/master/examples/wmt19)![Star](https://img.shields.io/github/stars/pytorch/fairseq.svg?style=social&label=Star)                                                          | 2019      |                  |                                                                                                       |
| Funnel Transformer   | Funnel-Transformer：Filtering out Sequential Redemption for Efficient Language Processing                                                                    | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2006.03236)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com//laiguokun/Funnel-Transformer)![Star](https://img.shields.io/github/stars/laiguokun/Funnel-Transformer.svg?style=social&label=Star)                                                          | 2020      |                  |                                                                                                       |
| Fuyu                 | Fuyu-8B: A Multimodal Architecture for AI Agents                                                                                                            | [![Paper](https://img.shields.io/badge/Blog-ydd7e6?style=for-the-badge)](https://www.adept.ai/blog/fuyu-8b)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/persimmon-ai-labs/adept-inference)![Star](https://img.shields.io/github/stars/persimmon-ai-labs/adept-inference.svg?style=social&label=Star)                                                 | 2023      |                  |                                                                                                       |
| Gemma                | Gemma：Open Models Based on Gemini Technology and Research                                                                                                   | [![Paper](https://img.shields.io/badge/Blog-ydd7e6?style=for-the-badge)](https://blog.google/technology/developers/gemma-open-models/)                                                                                                            | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://www.kaggle.com/models/google/gemma)                                                                                                                                                                     | 2023      |                  |                                                                                                       |
| Gemma2               | Gemma2: Open Models Based on Gemini Technology and Research                                                                                                 | [![Paper](https://img.shields.io/badge/Blog-ydd7e6?style=for-the-badge)](https://blog.google/technology/developers/google-gemma-2/)                                                                                                               | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://www.kaggle.com/models/google/gemma)                                                                                                                                                                     | 2023      |                  |                                                                                                       |
| OpenAI GPT           | Improving Language Understanding by Generative Pre-Training                                                                                                 | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)                                                | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/openai/finetune-transformer-lm)![Star](https://img.shields.io/github/stars/openai/finetune-transformer-lm.svg?style=social&label=Star)                                                       | 2018      | OpenAI           |                                                                                                       |
| GPT Neo              | The Pile: An 800GB Dataset of Diverse Text for Language Modeling                                                                                            | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2101.00027)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/EleutherAI/gpt-neo)![Star](https://img.shields.io/github/stars/EleutherAI/gpt-neo.svg?style=social&label=Star)                                                                               | 2020      |                  |                                                                                                       |
| GPTBigCode           | SantaCoder: don't reach for the stars!                                                                                                                      | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2301.03988)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/EleutherAI/gpt-neo)                                                                                                                                                                          | 2023      |                  |                                                                                                       |
| OpenAI GPT2          | Language Models are Unsupervised Multitask Learners                                                                                                         | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)                                                                  | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://openai.com/index/better-language-models/)                                                                                                                                                               | 2019      | 1.5B OpenAI      |                                                                                                       |
| GPT-Sw3              | Lessons Learned from GPT-SW3: Building the First Large-Scale Generative Language Model for Swedish                                                          | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](http://www.lrec-conf.org/proceedings/lrec2022/pdf/2022.lrec-1.376.pdf)                                                                                                  | ![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)                                                                                                                                                                                                                   | 2022      |                  |                                                                                                       |
| HerBERT              | KLEJ: Comprehensive Benchmark for Polish Language Understanding                                                                                             | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://www.aclweb.org/anthology/2020.acl-main.111.pdf)                                                                                                                 | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/allegro/HerBERT)![Star](https://img.shields.io/github/stars/allegro/HerBERT.svg?style=social&label=Star)                                                                                     | 2020      |                  |                                                                                                       |
| I-BERT               | I-BERT: Integer-only BERT Quantization                                                                                                                      | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2101.01321)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/kssteven418/I-BERT)![Star](https://img.shields.io/github/stars/kssteven418/I-BERT.svg?style=social&label=Star)                                                                               | 2021      |                  |                                                                                                       |
| Jamba                | Introducing Jamba: AI21's Groundbreaking SSM-Transformer Model                                                                                              | [![Paper](https://img.shields.io/badge/Blog-ydd7e6?style=for-the-badge)](https://www.ai21.com/blog/announcing-jamba)                                                                                                                              | ![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)                                                                                                                                                                                                                   | 2024      |                  |                                                                                                       |
| Jukebox              | Jukebox: A generative model for music                                                                                                                       | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/pdf/2005.00341.pdf)                                                                                                                                   | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/openai/jukebox)![Star](https://img.shields.io/github/stars/openai/jukebox.svg?style=social&label=Star)                                                                                       | 2020      |                  |                                                                                                       |
| LED                  | Longformer: The Long-Document Transformer                                                                                                                   | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2004.05150)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://colab.research.google.com/drive/12INTTR6n64TzS4RrXZxMSXfrOd9Xzamo?usp=sharing)                                                                                                                          | 2020      |                  |                                                                                                       |
| LLaMA                | LLaMA: Open and Efficient Foundation Language Models                                                                                                        | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2302.13971)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/meta-llama/llama)![Star](https://img.shields.io/github/stars/meta-llama/llama.svg?style=social&label=Star)                                                                                   | 2023      |                  |                                                                                                       |
| Llama2               | LLaMA: Open Foundation and Fine-Tuned Chat Models                                                                                                           | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/)                                                                          | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/meta-llama/llama)![Star](https://img.shields.io/github/stars/meta-llama/llama.svg?style=social&label=Star)                                                                                   | 2023      |                  |                                                                                                       |
| Llama3               | Introducing Meta Llama 3: The most capable openly available LLM to date                                                                                     | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://ai.meta.com/blog/meta-llama-3/)                                                                                                                                 | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/meta-llama/llama3)![Star](https://img.shields.io/github/stars/meta-llama/llama3.svg?style=social&label=Star)                                                                                 | 2024      |                  |                                                                                                       |
| Longformer           | Longformer: The Long-Document Transformer                                                                                                                   | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/pdf/2004.05150.pdf)                                                                                                                                   | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/allenai/longformer)![Star](https://img.shields.io/github/stars/allenai/longformer.svg?style=social&label=Star)                                                                               | 2020      |                  |                                                                                                       |
| LongT5               | LongT5: Efficient Text-To-Text Transformer for Long Sequences                                                                                               | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2112.07916)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/allenai/longformer)![Star](https://img.shields.io/github/stars/allenai/longformer.svg?style=social&label=Star)                                                                               | 2021      |                  |                                                                                                       |
| LUKE                 | LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention                                                                           | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2112.07916)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/allenai/longformer)![Star](https://img.shields.io/github/stars/allenai/longformer.svg?style=social&label=Star)                                                                               | 2020      |                  |                                                                                                       |
| M2M100               | Beyond English-Centric Multilingual Machine Translation                                                                                                     | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2010.11125)                                                                                                                                       | ![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)                                                                                                                                                                                                                   | 2020      |                  |                                                                                                       |
| MADLAD-400           | MADLAD-400：A Multilingual And Document-Level Large Audited Dataset]（MADLAD-400：A Multilingual And Document-Level Large Audited Dataset                      | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2309.04662)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/google-research/tree/master/madlad_400)![Star](https://img.shields.io/github/stars/google-research/google-research.svg?style=social&label=Star)                              | 2023      |                  |                                                                                                       |
| Mamba                | Mamba：Linear-Time Sequence Modeling with Selective State Spaces                                                                                             | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2312.00752)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/state-spaces/mamba)![Star](https://img.shields.io/github/stars/state-spaces/mamba.svg?style=social&label=Star)                                                                               | 2024      |                  |                                                                                                       |
| MarianMT             | A framework for translation models, using the same models as BART.                                                                                          | [![Paper](https://img.shields.io/badge/Blog-ydd7e6?style=for-the-badge)](https://github.com/huggingface/transformers/blob/main/docs/source/en/model_doc/marian.md)                                                                                | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/huggingface/transformers/blob/main/docs/source/en/model_doc/marian.md)                                                                                                                       | 2024      |                  |                                                                                                       |
| MarkupLM             | MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding                                                                 | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2110.08518)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/microsoft/unilm/tree/master/markuplm)![Star](https://img.shields.io/github/stars/microsoft/unilm.svg?style=social&label=Star)                                                                | 2021      |                  |                                                                                                       |
| MBart and MBart-50   | Multilingual Denoising Pre-training for Neural Machine Translation                                                                                          | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2001.08210)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/pytorch/fairseq/tree/master/examples/mbart)![Star](https://img.shields.io/github/stars/pytorch/fairseq.svg?style=social&label=Star)                                                          | 2020      |                  |                                                                                                       |
| Mega                 | Mega: Moving Average Equipped Gated Attention                                                                                                               | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2209.10655)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/mega)![Star](https://img.shields.io/github/stars/facebookresearch/mega.svg?style=social&label=Star)                                                                         | 2022      |                  |                                                                                                       |
| MegatronBERT         | Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism                                                                       | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1909.08053)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/NVIDIA/Megatron-LM)![Star](https://img.shields.io/github/stars/NVIDIA/Megatron-LM.svg?style=social&label=Star)                                                                               | 2019      |                  |                                                                                                       |
| MegatronGPT2         | Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism                                                                       | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1909.08053)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/NVIDIA/Megatron-LM)![Star](https://img.shields.io/github/stars/NVIDIA/Megatron-LM.svg?style=social&label=Star)                                                                               | 2019      |                  |                                                                                                       |
| Mistral              | Mistral-7B is a decoder-only Transformer                                                                                                                    | [![Paper](https://img.shields.io/badge/Blog-ydd7e6?style=for-the-badge)](https://mistral.ai/news/announcing-mistral-7b/)                                                                                                                          | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/persimmon-ai-labs/adept-inference)                                                                                                                                                           | 2023      |                  |                                                                                                       |
| Mixtral              | a high-quality sparse mixture of experts models (SMoE) with open weights.                                                                                   | [![Paper](https://img.shields.io/badge/Blog-ydd7e6?style=for-the-badge)](https://mistral.ai/news/mixtral-of-experts/)                                                                                                                             | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/NVIDIA/Megatron-LM)                                                                                                                                                                          | 2023      |                  |                                                                                                       |
| mLUKE                | mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models                                                                       | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2110.08151)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/studio-ousia/luke)![Star](https://img.shields.io/github/stars/studio-ousia/luke.svg?style=social&label=Star)                                                                                 | 2021      |                  |                                                                                                       |
| MobileBERT           | MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices                                                                                       | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2004.02984)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/google-research/tree/master/mobilebert)![Star](https://img.shields.io/github/stars/google-research/google-research.svg?style=social&label=Star)                              | 2020      |                  |                                                                                                       |
| MPNet                | MPNet：Masked and Permuted Pre-training for Language Understanding                                                                                           | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2004.09297)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/microsoft/MPNet)![Star](https://img.shields.io/github/stars/microsoft/MPNet.svg?style=social&label=Star)                                                                                     | 2020      |                  |                                                                                                       |
| MPT                  | MPT models are GPT-style decoder-only transformers with several improvements                                                                                | [![Paper](https://img.shields.io/badge/Blog-ydd7e6?style=for-the-badge)](https://www.mosaicml.com/blog/mpt-7b)                                                                                                                                    | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/mosaicml/llm-foundry)![Star](https://img.shields.io/github/stars/mosaicml/llm-foundry.svg?style=social&label=Star)                                                                           | 2023      |                  |                                                                                                       |
| MRA                  | Multi Resolution Analysis (MRA) for Approximate Self-Attention                                                                                              | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2207.10284)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/mlpen/mra-attention)![Star](https://img.shields.io/github/stars/mlpen/mra-attention.svg?style=social&label=Star)                                                                             | 2022      |                  |                                                                                                       |
| MT5                  | mT5: A massively multilingual pre-trained text-to-text transformer                                                                                          | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2010.11934)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/multilingual-t5)![Star](https://img.shields.io/github/stars/google-research/multilingual-t5.svg?style=social&label=Star)                                                     | 2020      |                  |                                                                                                       |
| MVP                  | MVP: Multi-task Supervised Pre-training for Natural Language Generation                                                                                     | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2206.12131)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/RUCAIBox/MVP)![Star](https://img.shields.io/github/stars/RUCAIBox/MVP.svg?style=social&label=Star)                                                                                           | 2022      |                  |                                                                                                       |
| Nezha                | NEZHA: Neural Contextualized Representation for Chinese Language Understanding                                                                              | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1909.00204)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/huawei-noah/Pretrained-Language-Model)![Star](https://img.shields.io/github/stars/huawei-noah/Pretrained-Language-Model.svg?style=social&label=Star)                                         | 2019      |                  |                                                                                                       |
| NLLB                 | No Language Left Behind: Scaling Human-Centered Machine Translation                                                                                         | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2207.04672)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/fairseq/tree/nllb)![Star](https://img.shields.io/github/stars/facebookresearch/fairseq.svg?style=social&label=Star)                                                         | 2022      |                  |                                                                                                       |
| NLLB-MOE             | No Language Left Behind: Scaling Human-Centered Machine Translation                                                                                         | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2207.04672)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/fairseq/tree/nllb)![Star](https://img.shields.io/github/stars/facebookresearch/fairseq.svg?style=social&label=Star)                                                         | 2022      |                  |                                                                                                       |
| Nyströmformer        | Nyströmformer：A Nyström-Based Algorithm for Approximating Self-Attention                                                                                    | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2102.03902)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/mlpen/Nystromformer)![Star](https://img.shields.io/github/stars/mlpen/Nystromformer.svg?style=social&label=Star)                                                                             | 2021      |                  |                                                                                                       |
| OLMo                 | OLMo: Accelerating the Science of Language Models                                                                                                           | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2402.00838)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/allenai/OLMo/tree/main/olmo)![Star](https://img.shields.io/github/stars/allenai/OLMo.svg?style=social&label=Star)                                                                            | 2024      |                  |                                                                                                       |
| Open-Llama           | The Open-Llama model was proposed in the open source Open-Llama project by community developer s-JoL.                                                       | ![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)                                                                                                                                                                           | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://huggingface.co/models?search=openllama)                                                                                                                                                                 | 2023      |                  |                                                                                                       |
| OPT                  | Open Pre-trained Transformer Language Models                                                                                                                | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/pdf/2205.01068)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/metaseq)![Star](https://img.shields.io/github/stars/facebookresearch/metaseq.svg?style=social&label=Star)                                                                   | 2022      |                  |                                                                                                       |
| Pegasus              | PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization                                                                            | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/pdf/1912.08777.pdf)                                                                                                                                   | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/pegasus)![Star](https://img.shields.io/github/stars/google-research/pegasus.svg?style=social&label=Star)                                                                     | 2019      |                  |                                                                                                       |
| PEGASUS-X            | Investigating Efficiently Extending Transformers for Long Input Summarization                                                                               | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2208.04347)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/pegasus)![Star](https://img.shields.io/github/stars/google-research/pegasus.svg?style=social&label=Star)                                                                     | 2022      |                  |                                                                                                       |
| Persimmon            | Persimmon-8B is a fully permissively-licensed model with approximately 8 billion parameters                                                                 | ![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)                                                                                                                                                                           | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/persimmon-ai-labs/adept-inference)![Star](https://img.shields.io/github/stars/persimmon-ai-labs/adept-inference.svg?style=social&label=Star)                                                 | 2022      |                  |                                                                                                       |
| Phi                  | Textbooks Are All You Need                                                                                                                                  | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2309.05463)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](ttps://huggingface.co/microsoft/phi-1)                                                                                                                                                                          | 2023      |                  |                                                                                                       |
| Phi-3                | Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone                                                                               | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2404.14219)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)                                                                                                                                                        | 2024      |                  |                                                                                                       |
| PhoBERT              | PhoBERT: Pre-trained language models for Vietnamese                                                                                                         | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://www.aclweb.org/anthology/2020.findings-emnlp.92.pdf)                                                                                                            | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/VinAIResearch/PhoBERT)![Star](https://img.shields.io/github/stars/VinAIResearch/PhoBERT.svg?style=social&label=Star)                                                                         | 2022      |                  |                                                                                                       |
| PLBart               | Unified Pre-training for Program Understanding and Generation                                                                                               | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.06333)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/wasiahmad/PLBART)![Star](https://img.shields.io/github/stars/wasiahmad/PLBART.svg?style=social&label=Star)                                                                                   | 2021      |                  |                                                                                                       |
| ProphetNet           | ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training                                                                                  | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2001.04063)                                                                                                                                       | ![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)                                                                                                                                                                                                                   | 2020      |                  |                                                                                                       |
| QDQBERT              | Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation                                                                       | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2004.09602)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/wasiahmad/PLBART)                                                                                                                                                                            | 2020      |                  |                                                                                                       |
| Qwen                 | Qwen is a comprehensive language model series that encompasses distinct models with varying parameter counts.                                               | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2309.16609)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/QwenLM/Qwen)![Star](https://img.shields.io/github/stars/QwenLM/Qwen.svg?style=social&label=Star)                                                                                             | 2023      |                  |                                                                                                       |
| Qwen2                | Qwen2 is the new model series of large language models from the Qwen team.                                                                                  | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2407.10671)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/QwenLM/Qwen2)![Star](https://img.shields.io/github/stars/QwenLM/Qwen2.svg?style=social&label=Star)                                                                                           | 2024      |                  |                                                                                                       |
| Qwen-VL              | Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond                                                        | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2308.12966)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/QwenLM/Qwen-VL)![Star](https://img.shields.io/github/stars/QwenLM/Qwen-VL.svg?style=social&label=Star)                                                                                       | 2023      |                  |                                                                                                       |
| Qwen2MoE             | Qwen1.5-MoE: Matching 7B Model Performance with 1/3 Activated Parameters                                                                                    | [![Paper](https://img.shields.io/badge/BLog-ydd7e6?style=for-the-badge)](https://qwenlm.github.io/blog/qwen-moe/)                                                                                                                                 | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://huggingface.co/Qwen)                                                                                                                                                                                    | 2024      |                  |                                                                                                       |
| REALM                | REALM: Retrieval-Augmented Language Model Pre-Training                                                                                                      | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2002.08909)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/language/tree/master/language/realm)![Star](https://img.shields.io/github/stars/google-research/language.svg?style=social&label=Star)                                        | 2020      |                  |                                                                                                       |
| RecurrentGemma       | RecurrentGemma: Moving Past Transformers for Efficient Open Language Models                                                                                 | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://storage.googleapis.com/deepmind-media/gemma/recurrentgemma-report.pdf)                                                                                          | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-deepmind/recurrentgemma)![Star](https://img.shields.io/github/stars/google-deepmind/recurrentgemma.svg?style=social&label=Star)                                                       | 2024      |                  |                                                                                                       |
| Reformer             | Reformer: The Efficient Transformer                                                                                                                         | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2001.04451.pdf)                                                                                                                                   | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google/trax/tree/master/trax/models/reformer)![Star](https://img.shields.io/github/stars/google/trax.svg?style=social&label=Star)                                                            | 2020      |                  |                                                                                                       |
| RemBERT              | Rethinking Embedding Coupling in Pre-trained Language Models                                                                                                | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2010.12821)                                                                                                                                       | ![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)                                                                                                                                                                                                                   | 2020      |                  |                                                                                                       |
| RetriBERT            | Explain Anything Like I’m Five: A Model for Open Domain Long Form Question Answering                                                                        | [![Paper](https://img.shields.io/badge/BLOG-ydd7e6?style=for-the-badge)](https://yjernite.github.io/lfqa.html)                                                                                                                                    | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/huggingface/transformers/tree/main/examples/research-projects/distillation)                                                                                                                  | 2020      |                  |                                                                                                       |
| RoBERTa              | RoBERTa: A Robustly Optimized BERT Pretraining Approach                                                                                                     | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1907.11692)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/pytorch/fairseq/tree/master/examples/roberta)![Star](https://img.shields.io/github/stars/pytorch/fairseq.svg?style=social&label=Star)                                                        | 2019      |                  |                                                                                                       |
| RoBERTa-PreLayerNorm | fairseq: A Fast, Extensible Toolkit for Sequence Modeling                                                                                                   | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1904.01038)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/princeton-nlp/DinkyTrain)![Star](https://img.shields.io/github/stars/princeton-nlp/DinkyTrain.svg?style=social&label=Star)                                                                   | 2022      |                  |                                                                                                       |
| RoCBert              | RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining                                                                                        | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://aclanthology.org/2022.acl-long.65.pdf)                                                                                                                          | ![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)                                                                                                                                                                                                                   | 2022      |                  |                                                                                                       |
| RoFormer             | RoFormer: Enhanced Transformer with Rotary Position Embedding                                                                                               | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://aclanthology.org/2022.acl-long.65.pdf)                                                                                                                          | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/ZhuiyiTechnology/roformer)![Star](https://img.shields.io/github/stars/ZhuiyiTechnology/roformer.svg?style=social&label=Star)                                                                 | 2021      |                  |                                                                                                       |
| RWKV-LM              | RWKV is an RNN with transformer-level LLM performance                                                                                                       | -                                                                                                                                                                                                                                                 | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/BlinkDL/RWKV-LM)![Star](https://img.shields.io/github/stars/BlinkDL/RWKV-LM.svg?style=social&label=Star)                                                                                     | 2022      |                  |                                                                                                       |
| RWKV-4.0             | RWKV: Reinventing RNNs for the Transformer Era                                                                                                              | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2305.13048)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/BlinkDL/RWKV-LM)![Star](https://img.shields.io/github/stars/BlinkDL/RWKV-LM.svg?style=social&label=Star)                                                                                     | 2023      |                  |                                                                                                       |
| RWKV-5/6 Eagle/Finch | Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence                                                                                      | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2404.05892)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/BlinkDL/RWKV-LM)![Star](https://img.shields.io/github/stars/BlinkDL/RWKV-LM.svg?style=social&label=Star)                                                                                     | 2024      |                  |                                                                                                       |
| Splinter             | Few-Shot Question Answering by Pretraining Span Selection                                                                                                   | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2101.00438)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/oriram/splinter)![Star](https://img.shields.io/github/stars/oriram/splinter.svg?style=social&label=Star)                                                                                     | 2021      |                  |                                                                                                       |
| SqueezeBERT          | SqueezeBERT: What can computer vision teach NLP about efficient neural networks?                                                                            | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2006.11316)                                                                                                                                       | ![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)                                                                                                                                                                                                                   | 2020      |                  |                                                                                                       |
| StableLM             | StableLM-3B-4E1T                                                                                                                                            | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://stability.wandb.io/stability-llm/stable-lm/reports/StableLM-3B-4E1T--VmlldzoyMjU4?accessToken=u3zujipenkx5g7rtcj9qojjgxpconyjktjkli2po09nffrffdhhchq045vp0wyfo) | ![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)                                                                                                                                                                                                                   | 2024      |                  |                                                                                                       |
| Starcoder2           | StarCoder 2 and The Stack v2: The Next Generation                                                                                                           | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2402.19173)                                                                                                                                       | ![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)                                                                                                                                                                                                                   | 2024      |                  |                                                                                                       |
| SwitchTransformers   | Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity                                                                | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2101.03961)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google/flaxformer/tree/main/flaxformer/architectures/moe)![Star](https://img.shields.io/github/stars/google/flaxformer.svg?style=social&label=Star)                                          | 2021      |                  |                                                                                                       |
| T5                   | Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer                                                                           | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/pdf/1910.10683.pdf)                                                                                                                                   | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/text-to-text-transfer-transformer)![Star](https://img.shields.io/github/stars/google-research/text-to-text-transfer-transformer.svg?style=social&label=Star)                 | 2023      |                  |                                                                                                       |
| T5v1.1               | Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer                                                                           | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/pdf/1910.10683.pdf)                                                                                                                                   | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/text-to-text-transfer-transformer)![Star](https://img.shields.io/github/stars/google-research/text-to-text-transfer-transformer.svg?style=social&label=Star)                 | 2023      |                  |                                                                                                       |
| TAPEX                | TAPEX: Table Pre-training via Learning a Neural SQL Executor                                                                                                | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2107.07653)                                                                                                                                       | ![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)                                                                                                                                                                                                                   | 2021      |                  |                                                                                                       |
| Transformer XL       | Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context                                                                                     | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1901.02860)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/kimiyoung/transformer-xl)                                                                                                                                                                    | 2019      |                  |                                                                                                       |
| UL2                  | Unifying Language Learning Paradigms                                                                                                                        | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/pdf/2205.05131v1.pdf)                                                                                                                                 | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/google-research/tree/master/ul2)![Star](https://img.shields.io/github/stars/google-research/google-research.svg?style=social&label=Star)                                     | 2022      |                  |                                                                                                       |
| UMT5                 | UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining                                                                | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://openreview.net/forum?id=kXwdL1cWOAi)                                                                                                                            | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/t5x)![Star](https://img.shields.io/github/stars/google-research/t5x.svg?style=social&label=Star)                                                                             | 2024      |                  |                                                                                                       |
| X-MOD                | Lifting the Curse of Multilinguality by Pre-training Modular Transformers                                                                                   | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](http://dx.doi.org/10.18653/v1/2022.naacl-main.255)                                                                                                                      | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/fairseq/tree/58cc6cca18f15e6d56e3f60c959fe4f878960a60/fairseq/models/xmod)![Star](https://img.shields.io/github/stars/facebookresearch/fairseq.svg?style=social&label=Star) | 2022      |                  |                                                                                                       |
| XGLM                 | Few-shot Learning with Multilingual Language Models                                                                                                         | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2112.10668)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/pytorch/fairseq/tree/main/examples/xglm)![Star](https://img.shields.io/github/stars/facebookresearch/fairseq.svg?style=social&label=Star)                                                    | 2021      |                  |                                                                                                       |
| XLM                  | Cross-lingual Language Model Pretraining                                                                                                                    | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1901.07291)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/XLM/)![Star](https://img.shields.io/github/stars/facebookresearch/XLM.svg?style=social&label=Star)                                                                          | 2019      |                  |                                                                                                       |
| XLM-ProphetNet       | ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training                                                                                  | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2001.04063)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/XLM/)![Star](https://img.shields.io/github/stars/facebookresearch/XLM.svg?style=social&label=Star)                                                                          | 2020      |                  |                                                                                                       |
| XLM-RoBERTa          | Unsupervised Cross-lingual Representation Learning at Scale                                                                                                 | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1911.02116)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/pytorch/fairseq/tree/master/examples/xlmr)![Star](https://img.shields.io/github/stars/pytorch/fairseq.svg?style=social&label=Star)                                                           | 2019      |                  |                                                                                                       |
| XLM-RoBERTa-XL       | Larger-Scale Transformers for Multilingual Masked Language Modeling                                                                                         | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2105.00572)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/pytorch/fairseq/tree/master/examples/xlmr)![Star](https://img.shields.io/github/stars/pytorch/fairseq.svg?style=social&label=Star)                                                           | 2021      |                  |                                                                                                       |
| XLM-V                | XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models                                                                          | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2301.10472)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/stefan-it/xlm-v-experiments)![Star](https://img.shields.io/github/stars/stefan-it/xlm-v-experiments.svg?style=social&label=Star)                                                             | 2023      |                  |                                                                                                       |
| XLNet                | XLNet: Generalized Autoregressive Pretraining for Language Understanding                                                                                    | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1906.08237)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/zihangdai/xlnet/)![Star](https://img.shields.io/github/stars/zihangdai/xlnet.svg?style=social&label=Star)                                                                                    | 2019      |                  |                                                                                                       |
| YOSO                 | You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling                                                                            | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2111.09714)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/mlpen/YOSO)![Star](https://img.shields.io/github/stars/mlpen/YOSO.svg?style=social&label=Star)                                                                                               | 2021      |                  |                                                                                                       |
|                      |                                                                                                                                                             |                                                                                                                                                                                                                                                   |                                                                                                                                                                                                                                                                                         |           |                  |                                                                                                       |

- Encoder Decoder Models
    
- RAG