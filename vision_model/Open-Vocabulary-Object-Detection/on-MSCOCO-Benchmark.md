### on-MSCOCO-Benchmark

| Model / Methods                  | Title                                                                                                       | Paper Link                                                                                                                                                                                                                                          | Code Link                                                                                                                                                                                                                                                 | Published | AP(0.5⬆️) coco | Keywords  | Venue     |
| -------------------------------- | ----------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------- | -------------- | --------- | --------- |
| Cooperative Foundational Models  | Enhancing Novel Object Detection via Cooperative Foundational Models                                        | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2311.12068v2)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/rohit901/cooperative-foundational-models)![Star](https://img.shields.io/github/stars/rohit901/cooperative-foundational-models.svg?style=social&label=Star)     | 2023      | 50.3           |           |           |
| DE-ViT                           | Detect Everything with Few Examples                                                                         | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2309.12969v3)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/mlzxy/devit)![Star](https://img.shields.io/github/stars/mlzxy/devit.svg?style=social&label=Star)                                                               | 2023      | 50             |           |           |
| DITO                             | Region-centric Image-Language Pretraining for Open-Vocabulary Detection                                     | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2310.00161v2)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/google-research/tree/master/fvlm/dito)![Star](https://img.shields.io/github/stars/google-research/google-research.svg?style=social&label=Star) | 2023      | 46.1           |           |           |
| OV-DQUO<br />(RN50x4)            | OV-DQUO: Open-Vocabulary DETR with Denoising Text Query Training and Open-World Unknown Objects Supervision | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2405.17913v1)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/xiaomoguhz/ov-dquo)![Star](https://img.shields.io/github/stars/xiaomoguhz/ov-dquo.svg?style=social&label=Star)                                                 | 2024      | 45.6           |           |           |
| LP-OVOD<br />(OWL-ViT Proposals) | LP-OVOD: Open-Vocabulary Object Detection by Linear Probing                                                 | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2310.17109v2)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/vinairesearch/lp-ovod)![Star](https://img.shields.io/github/stars/vinairesearch/lp-ovod.svg?style=social&label=Star)                                           | 2023      | 44.9           |           |           |
| CLIPSelf                         | CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction                           | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2310.01403v2)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/wusize/clipself)![Star](https://img.shields.io/github/stars/wusize/clipself.svg?style=social&label=Star)                                                       | 2023      | 44.3           |           |           |
| CORA+                            | CORA: Adapting CLIP for Open-Vocabulary Detection with Region Prompting and Anchor Pre-Matching             | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2303.13076v1)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/tgxs002/cora)![Star](https://img.shields.io/github/stars/tgxs002/cora.svg?style=social&label=Star)                                                             | 2023      | 43.1           |           | CVPR 2023 |
| BARON                            | Aligning Bag of Regions for Open-Vocabulary Object Detection                                                | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2302.13996v1)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/wusize/ovdet)![Star](https://img.shields.io/github/stars/wusize/ovdet.svg?style=social&label=Star)                                                             | 2023      | 42.7           |           | CVPR 2023 |
| CORA                             | CORA: Adapting CLIP for Open-Vocabulary Detection with Region Prompting and Anchor Pre-Matching             | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2303.13076v1)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/tgxs002/cora)![Star](https://img.shields.io/github/stars/tgxs002/cora.svg?style=social&label=Star)                                                             | 2023      | 41.7           |           | CVPR 2023 |
| RALF                             | Retrieval-Augmented Open-Vocabulary Object Detection                                                        | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](http://openaccess.thecvf.com//content/CVPR2024/papers/Kim_Retrieval-Augmented_Open-Vocabulary_Object_Detection_CVPR_2024_paper.pdf)                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/mlvlab/RALF)![Star](https://img.shields.io/github/stars/mlvlab/RALF.svg?style=social&label=Star)                                                               | 2024      | 41.3           |           | CVPR 2024 |
| LP-OVOD                          | LP-OVOD: Open-Vocabulary Object Detection by Linear Probing                                                 | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2310.17109v2)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/vinairesearch/lp-ovod)![Star](https://img.shields.io/github/stars/vinairesearch/lp-ovod.svg?style=social&label=Star)                                           | 2023      | 40.5           |           |           |
| Region-CLIP<br />(RN50x4-C4)     | RegionCLIP: Region-based Language-Image Pretraining                                                         | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](http://openaccess.thecvf.com//content/CVPR2022/html/Zhong_RegionCLIP_Region-Based_Language-Image_Pretraining_CVPR_2022_paper.html)                                        | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/microsoft/regionclip)![Star](https://img.shields.io/github/stars/microsoft/regionclip.svg?style=social&label=Star)                                             | 2021      | 39.3           | microsoft | CVPR 2022 |
| OV-DQUO<br/>(R50)                | OV-DQUO: Open-Vocabulary DETR with Denoising Text Query Training and Open-World Unknown Objects Supervision | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2405.17913v1)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/xiaomoguhz/ov-dquo)![Star](https://img.shields.io/github/stars/xiaomoguhz/ov-dquo.svg?style=social&label=Star)                                                 | 2024      | 39.2           |           |           |
| Object-Centric-OVD               | Bridging the Gap between Object and Image-level Representations for Open-Vocabulary Detection               | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2207.03482v3)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/mmaaz60/mvits_for_class_agnostic_od)![Star](https://img.shields.io/github/stars/mmaaz60/mvits_for_class_agnostic_od.svg?style=social&label=Star)               | 2022      | 36.9           |           | ECCV 2022 |
| CLIM<br/>(RN50)                  | CLIM: Contrastive Language-Image Mosaic for Region Representation                                           | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2312.11376v2)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/wusize/clim)![Star](https://img.shields.io/github/stars/wusize/clim.svg?style=social&label=Star)                                                               | 2023      | 36.9           |           | AAAI 2024 |
| OADP<br/>(G-OVD)]                | Object-Aware Distillation Pyramid for Open-Vocabulary Object Detection                                      | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](http://openaccess.thecvf.com//content/CVPR2023/html/Wang_Object-Aware_Distillation_Pyramid_for_Open-Vocabulary_Object_Detection_CVPR_2023_paper.html)                     | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/lutingwang/oadp)![Star](https://img.shields.io/github/stars/lutingwang/oadp.svg?style=social&label=Star)                                                       | 2023      | 35.6           |           | CVPR 2023 |
| VL-PLM<br/>(RN50)                | Exploiting Unlabeled Data with Vision and Language Models for Object Detection                              | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2207.08954v1)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/xiaofeng94/vl-plm)![Star](https://img.shields.io/github/stars/xiaofeng94/vl-plm.svg?style=social&label=Star)                                                   | 2022      | 34.4           |           |           |
| CFM-ViT                          | Contrastive Feature Masking Open-Vocabulary Vision Transformer                                              | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://paperswithcode.com/paper/contrastive-feature-masking-open-vocabulary)                                                                                             | ![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)                                                                                                                                                                                     | 2023      | 34.1           |           | ICCV 2023 |
| MEDet<br/>(RN50)                 | Open Vocabulary Object Detection with Proposal Mining and Prediction Equalization                           | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2206.11134v4)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/peixianchen/medet)![Star](https://img.shields.io/github/stars/peixianchen/medet.svg?style=social&label=Star)                                                   | 2022      | 32.6           |           |           |
| Region-CLIP<br/>(RN50-C4)        | RegionCLIP: Region-based Language-Image Pretraining                                                         | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](http://openaccess.thecvf.com//content/CVPR2022/html/Zhong_RegionCLIP_Region-Based_Language-Image_Pretraining_CVPR_2022_paper.html)                                        | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/microsoft/regionclip)![Star](https://img.shields.io/github/stars/microsoft/regionclip.svg?style=social&label=Star)                                             | 2022      | 31.4           |           | CVPR 2022 |
| OVAD-Baseline                    | Open-vocabulary Attribute Detection                                                                         | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](http://openaccess.thecvf.com//content/CVPR2023/html/Bravo_Open-Vocabulary_Attribute_Detection_CVPR_2023_paper.html)                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/OVAD-Benchmark/ovad-bechmark-code)![Star](https://img.shields.io/github/stars/OVAD-Benchmark/ovad-bechmark-code.svg?style=social&label=Star)                   | 2022      | 30.0           |           | CVPR 2023 |
| OADP                             | Object-Aware Distillation Pyramid for Open-Vocabulary Object Detection                                      | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](http://openaccess.thecvf.com//content/CVPR2023/html/Wang_Object-Aware_Distillation_Pyramid_for_Open-Vocabulary_Object_Detection_CVPR_2023_paper.html)                     | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/lutingwang/oadp)![Star](https://img.shields.io/github/stars/lutingwang/oadp.svg?style=social&label=Star)                                                       | 2023      | 30.0           |           | CVPR 2023 |
| OV-DERT                          | Open-Vocabulary DETR with Conditional Matching                                                              | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2203.11876v2)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/yuhangzang/ov-detr)![Star](https://img.shields.io/github/stars/yuhangzang/ov-detr.svg?style=social&label=Star)                                                 | 2022      | 29.4           |           |           |
| LocOv<br/>(RN50-C4)]             | Localized Vision-Language Matching for Open-vocabulary Object Detection                                     | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2205.06160v2)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/lmb-freiburg/locov)![Star](https://img.shields.io/github/stars/lmb-freiburg/locov.svg?style=social&label=Star)                                                 | 2022      | 28.6           |           |           |
| Detic                            | Detecting Twenty-thousand Classes using Image-level Supervision                                             | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/2201.02605v3)                                                                                                                                       | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/Detic)![Star](https://img.shields.io/github/stars/facebookresearch/Detic.svg?style=social&label=Star)                                         | 2022      | 27.8           |           |           |
| ViLD                             | Open-vocabulary Object Detection via Vision and Language Knowledge Distillation                             | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://openreview.net/forum?id=lL3lnMbR4WU)                                                                                                                              | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://colab.research.google.com/drive/19LBqQg0cS36rTLL_TaXZ7Ka9KJGkxiSe?usp=sharing)                                                                                            | 2021      | 27.6           |           | ICIR 2022 |
| OVR-CNN                          | Open-Vocabulary Object Detection Using Captions                                                             | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](http://openaccess.thecvf.com//content/CVPR2021/html/Zareian_Open-Vocabulary_Object_Detection_Using_Captions_CVPR_2021_paper.html)                                         | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/alirezazareian/ovr-cnn)![Star](https://img.shields.io/github/stars/alirezazareian/ovr-cnn.svg?style=social&label=Star)                                         | 2021      | 22.8           |           | CVPR 2021 |
| HierKD                           | Open-Vocabulary One-Stage Detection with Hierarchical Visual-Language Knowledge Distillation                | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](http://openaccess.thecvf.com//content/CVPR2022/html/Ma_Open-Vocabulary_One-Stage_Detection_With_Hierarchical_Visual-Language_Knowledge_Distillation_CVPR_2022_paper.html) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/mengqidyangge/hierkd)![Star](https://img.shields.io/github/stars/mengqidyangge/hierkd.svg?style=social&label=Star)                                             | 2022      | 20.3           |           | CVPR 2022 |
|                                  |                                                                                                             |                                                                                                                                                                                                                                                     |                                                                                                                                                                                                                                                           |           |                |           |           |