### On-ImageNet-Benchmark

- [https://paperswithcode.com/sota/image-classification-on-imagenet](https://paperswithcode.com/sota/image-classification-on-imagenet)

| Model / Methods                              | Title                                                        | Paper Link                                                   | Code Link                                                    | Published  | Keywords        | Venue        |
| -------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------- | --------------- | ------------ |
| FireCaffe<br/>(GoogLeNet)                    | FireCaffe: near-linear acceleration of deep neural network training on compute clusters | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1511.00175v2) | -                                                            | 2015.10.31 |                 |              |
| ResNet                                       | Deep Residual Learning for Image Recognition                 | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1512.03385v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/tensorflow/models)![Star](https://img.shields.io/github/stars/tensorflow/models.svg?style=social&label=Star) | 2015.12.10 |                 | CVPR 2016    |
|                                              |                                                              |                                                              |                                                              |            |                 |              |
| Inception ResNet V2                          | Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1602.07261v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/Cadene/pretrained-models.pytorch)![Star](https://img.shields.io/github/stars/Cadene/pretrained-models.pytorch.svg?style=social&label=Star) | 2016.02.23 |                 |              |
| ResNet-200                                   | Identity Mappings in Deep Residual Networks                  | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1603.05027v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/KaimingHe/resnet-1k-layers)![Star](https://img.shields.io/github/stars/KaimingHe/resnet-1k-layers.svg?style=social&label=Star) | 2016.03.16 | kaiming         |              |
| WRN-50-2-bottleneck                          | Wide Residual Networks                                       | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1605.07146v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/szagoruyko/wide-residual-networks)![Star](https://img.shields.io/github/stars/szagoruyko/wide-residual-networks.svg?style=social&label=Star) | 2016.05.23 |                 |              |
| SimpleNetV1-9m-correct-labels                | Lets keep it simple, Using simple architectures to outperform deeper and more complex architectures | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1608.06037v8) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/Coderx7/SimpleNet)![Star](https://img.shields.io/github/stars/Coderx7/SimpleNet.svg?style=social&label=Star) | 2016.08.22 |                 |              |
| DenseNet-264                                 | Densely Connected Convolutional Networks                     | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1608.06993v5) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/liuzhuang13/DenseNet)![Star](https://img.shields.io/github/stars/liuzhuang13/DenseNet.svg?style=social&label=Star) | 2016.08.25 |                 | CVPR 2017    |
| Xception                                     | Xception: Deep Learning with Depthwise Separable Convolutions | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1610.02357v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/rwightman/pytorch-image-models)![Star](https://img.shields.io/github/stars/rwightman/pytorch-image-models.svg?style=social&label=Star) | 2016.10.07 |                 | CVPR 2017    |
| ResNeXt-101 64x4                             | Aggregated Residual Transformations for Deep Neural Networks | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1611.05431v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/ResNeXt)![Star](https://img.shields.io/github/stars/facebookresearch/ResNeXt.svg?style=social&label=Star) | 2016.11.16 |                 | CVPR 2017    |
|                                              |                                                              |                                                              |                                                              |            |                 |              |
| MobileNet-224 ×1.25                          | MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1704.04861v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/huggingface/pytorch-image-models)![Star](https://img.shields.io/github/stars/huggingface/pytorch-image-models.svg?style=social&label=Star) | 2017.04.17 |                 |              |
| Attention-92                                 | Residual Attention Network for Image Classification          | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1704.06904v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/tengshaofeng/ResidualAttentionNetwork-pytorch)![Star](https://img.shields.io/github/stars/tengshaofeng/ResidualAttentionNetwork-pytorch.svg?style=social&label=Star) | 2017.04.23 |                 | CVPR 2017    |
| ShuffleNet                                   | ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1707.01083v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/tensorpack/tensorpack/tree/master/examples/ImageNetModels)![Star](https://img.shields.io/github/stars/tensorpack/tensorpack.svg?style=social&label=Star) | 2017.07.04 |                 | CVPR 2018    |
| ResNet-101 (JFT-300M Finetuning)             | Revisiting Unreasonable Effectiveness of Data in Deep Learning Era | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1707.02968v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/Tencent/tencent-ml-images)![Star](https://img.shields.io/github/stars/Tencent/tencent-ml-images.svg?style=social&label=Star) | 2017.07.10 | Tencent         | ICCV 2017    |
| NASNET-A                                     | Learning Transferable Architectures for Scalable Image Recognition | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1707.07012v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/titu1994/neural-architecture-search)![Star](https://img.shields.io/github/stars/titu1994/neural-architecture-search.svg?style=social&label=Star) | 2017.07.21 |                 | CVPR 2018    |
| PNASNet-5                                    | Progressive Neural Architecture Search                       | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1712.00559v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/chenxi116/PNASNet.pytorch)![Star](https://img.shields.io/github/stars/chenxi116/PNASNet.pytorch.svg?style=social&label=Star) | 2017.12.02 |                 | ECCV 2018    |
|                                              |                                                              |                                                              |                                                              |            |                 |              |
| MobileNetV2                                  | MobileNetV2: Inverted Residuals and Linear Bottlenecks       | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1801.04381v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/tensorflow/models)![Star](https://img.shields.io/github/stars/tensorflow/models.svg?style=social&label=Star) | 2018.01.13 |                 | CVPR 2018    |
| AmoebaNet-A                                  | Regularized Evolution for Image Classifier Architecture Search | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1802.01548v7) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/DataCanvasIO/Hypernets)![Star](https://img.shields.io/github/stars/DataCanvasIO/Hypernets.svg?style=social&label=Star) | 2018.02.05 |                 |              |
| SWA                                          | Averaging Weights Leads to Wider Optima and Better Generalization | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1803.05407v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/wjmaddox/swa_gaussian)![Star](https://img.shields.io/github/stars/wjmaddox/swa_gaussian.svg?style=social&label=Star) | 2018.03.14 |                 |              |
| Inception v3                                 | What do Deep Networks Like to See?                           | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1803.08337v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/spalaciob/s2snets-reconstruction)![Star](https://img.shields.io/github/stars/spalaciob/s2snets-reconstruction.svg?style=social&label=Star) | 2018.03.22 |                 | CVPR 2018    |
| ResNeXt-101 32x48d                           | Exploring the Limits of Weakly Supervised Pretraining        | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1805.00932v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/ClassyVision)![Star](https://img.shields.io/github/stars/facebookresearch/ClassyVision.svg?style=social&label=Star) | 2018.05.02 |                 | ECCV 2018    |
| CoordConv ResNet-50                          | An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1807.03247v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/mkocabas/CoordConv-pytorch)![Star](https://img.shields.io/github/stars/mkocabas/CoordConv-pytorch.svg?style=social&label=Star) | 2018.07.09 |                 | NeurIPS 2018 |
| ShuffleNet V2                                | ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1807.11164v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/pytorch/vision)![Star](https://img.shields.io/github/stars/pytorch/vision.svg?style=social&label=Star) | 2018.07.30 |                 | ECCV 2018    |
| MnasNet-A3                                   | MnasNet: Platform-Aware Neural Architecture Search for Mobile | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1807.11626v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet)![Star](https://img.shields.io/github/stars/tensorflow/tpu.svg?style=social&label=Star) | 2018.07.31 |                 | CVPR 2019    |
| DropBlock                                    | DropBlock: A regularization method for convolutional networks | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1810.12890v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/miguelvr/dropblock)![Star](https://img.shields.io/github/stars/miguelvr/dropblock.svg?style=social&label=Star) | 2018.10.30 |                 | NeurIPS 2018 |
| GPIPE                                        | GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1811.06965v5) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/qubvel/efficientnet)![Star](https://img.shields.io/github/stars/qubvel/efficientnet.svg?style=social&label=Star) | 2018.11.16 |                 | NeurIPS 2019 |
| ESPNetv2                                     | ESPNetv2: A Light-weight, Power Efficient, and General Purpose Convolutional Neural Network | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1811.11431v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/sacmehta/ESPNetv2)![Star](https://img.shields.io/github/stars/sacmehta/ESPNetv2.svg?style=social&label=Star) | 2018.11.28 |                 |              |
| Proxyless                                    | ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1812.00332v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/MIT-HAN-LAB/ProxylessNAS)![Star](https://img.shields.io/github/stars/MIT-HAN-LAB/ProxylessNAS.svg?style=social&label=Star) | 2018.12.02 |                 | ICLR 2019    |
| ResNet-50-D                                  | Bag of Tricks for Image Classification with Convolutional Neural Networks | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1812.01187v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/rwightman/pytorch-image-models)![Star](https://img.shields.io/github/stars/rwightman/pytorch-image-models.svg?style=social&label=Star) | 2018.12.04 |                 | CVPR 2019    |
| FBNet-C                                      | FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1812.03443v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/mobile-vision)![Star](https://img.shields.io/github/stars/facebookresearch/mobile-vision.svg?style=social&label=Star) | 2018.12.09 |                 | CVPR 2019    |
|                                              |                                                              |                                                              |                                                              |            |                 |              |
| ColorNet<br/>(RHYLH with Conv Layer)         | ColorNet: Investigating the importance of color spaces for image classification | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1902.00267v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/kini5gowda/ColorNet)![Star](https://img.shields.io/github/stars/kini5gowda/ColorNet.svg?style=social&label=Star) | 2019.02.01 |                 |              |
| Graph-RISE                                   | Graph-RISE: Graph-Regularized Image Semantic Embedding       | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1902.10814v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/tensorflow/neural-structured-learning)![Star](https://img.shields.io/github/stars/tensorflow/neural-structured-learning.svg?style=social&label=Star) | 2019.02.04 |                 |              |
| MultiGrain PNASNet<br/>(500px)]              | MultiGrain: a unified image embedding for classes and instances | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1902.05509v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/multigrain)![Star](https://img.shields.io/github/stars/facebookresearch/multigrain.svg?style=social&label=Star) | 2019.02.14 |                 |              |
| SRM-ResNet-101                               | SRM : A Style-based Recalibration Module for Convolutional Neural Networks | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1903.10829v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/EvgenyKashin/SRMnet)![Star](https://img.shields.io/github/stars/EvgenyKashin/SRMnet.svg?style=social&label=Star) | 2019.03.26 |                 |              |
| Res2Net-101                                  | Res2Net: A New Multi-scale Backbone Architecture             | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1904.01169v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/rwightman/pytorch-image-models)![Star](https://img.shields.io/github/stars/rwightman/pytorch-image-models.svg?style=social&label=Star) | 2019.04.02 |                 |              |
| RandWire-WS                                  | Exploring Randomly Wired Neural Networks for Image Recognition | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1904.01569v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/seungwonpark/RandWireNN)![Star](https://img.shields.io/github/stars/seungwonpark/RandWireNN.svg?style=social&label=Star) | 2019.04.02 |                 | ICCV 2019    |
| Single-Path NAS                              | Single-Path NAS: Designing Hardware-Efficient ConvNets in less than 4 Hours | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1904.02877v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/dstamoulis/single-path-nas)![Star](https://img.shields.io/github/stars/dstamoulis/single-path-nas.svg?style=social&label=Star) | 2019.04.05 |                 |              |
| ACNet                                        | Adaptively Connected Neural Networks                         | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1904.03579v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/wanggrun/Adaptively-Connected-Neural-Networks)![Star](https://img.shields.io/github/stars/wanggrun/Adaptively-Connected-Neural-Networks.svg?style=social&label=Star) | 2019.04.07 |                 | CVPR 2019    |
| Oct-ResNet-152 (SE)                          | Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1904.05049v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/OctConv)![Star](https://img.shields.io/github/stars/facebookresearch/OctConv.svg?style=social&label=Star) | 2019.04.10 |                 | ICCV 2019    |
| ScaleNet-152                                 | Data-Driven Neuron Allocation for Scale Aggregation Networks | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1904.09460v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/Eli-YiLi/ScaleNet)![Star](https://img.shields.io/github/stars/Eli-YiLi/ScaleNet.svg?style=social&label=Star) | 2019.04.20 |                 | CVPR 2019    |
| LR-Net-26                                    | Local Relation Networks for Image Recognition                | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1904.11491v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/gan3sh500/local-relational-nets)![Star](https://img.shields.io/github/stars/gan3sh500/local-relational-nets.svg?style=social&label=Star) | 2019.04.25 |                 | ICCV 2019    |
| ResNet-50<br/>(UDA)                          | Unsupervised Data Augmentation for Consistency Training      | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1904.12848v6) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/uda)![Star](https://img.shields.io/github/stars/google-research/uda.svg?style=social&label=Star) | 2019.04.29 |                 | NeurIPS 2020 |
| ResNet-200<br/>(Fast AA)                     | Fast AutoAugment                                             | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1905.00397v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/kakaobrain/fast-autoaugment)![Star](https://img.shields.io/github/stars/kakaobrain/fast-autoaugment.svg?style=social&label=Star) | 2019.05.01 |                 | NeurIPS 2019 |
| ResNeXt-101 32x16d<br/>(semi-weakly sup.)    | Billion-scale semi-supervised learning for image classification | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1905.00546v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/rwightman/pytorch-image-models)![Star](https://img.shields.io/github/stars/rwightman/pytorch-image-models.svg?style=social&label=Star) | 2019.05.02 |                 |              |
| ResNeXt-101<br/>(CutMix)                     | CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1905.04899v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/clovaai/CutMix-PyTorch)![Star](https://img.shields.io/github/stars/clovaai/CutMix-PyTorch.svg?style=social&label=Star) | 2019.05.13 |                 | ICCV 2019    |
| SGE-ResNet50                                 | Spatial Group-wise Enhance: Improving Semantic Feature Learning in Convolutional Networks | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1905.09646v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/implus/PytorchInsight)![Star](https://img.shields.io/github/stars/implus/PytorchInsight.svg?style=social&label=Star) | 2019.05.23 |                 |              |
| CondConv                                     | CondConv: Conditionally Parameterized Convolutions for Efficient Inference | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1905.09646v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/implus/PytorchInsight)![Star](https://img.shields.io/github/stars/implus/PytorchInsight.svg?style=social&label=Star) | 2019.05.23 |                 |              |
| EfficientNet                                 | EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks | [![Paper](https://img.shields.io/badge/Paper-ydd7e6?style=for-the-badge)](https://arxiv.org/abs/1905.11946) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet)![Star](https://img.shields.io/github/stars/tensorflow/tpu.svg?style=social&label=Star) | 2019.05.28 | tensorflow      |              |
| DiCENet                                      | DiCENet: Dimension-wise Convolutions for Efficient Networks  | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1906.03516v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/sacmehta/EdgeNets/)![Star](https://img.shields.io/github/stars/sacmehta/EdgeNets.svg?style=social&label=Star) | 2019.06.08 |                 |              |
| FixResNeXt-101 32x48d                        | Fixing the train-test resolution discrepancy                 | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1906.06423v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/FixRes)![Star](https://img.shields.io/github/stars/facebookresearch/FixRes.svg?style=social&label=Star) | 2019.06.14 |                 | NeurIPS 2019 |
| DenseNAS                                     | Densely Connected Search Space for More Flexible Neural Architecture Search | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1906.09607v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/JaminFong/DenseNAS)![Star](https://img.shields.io/github/stars/JaminFong/DenseNAS.svg?style=social&label=Star) | 2019.06.23 |                 | CVPR 2020    |
| FairNAS                                      | FairNAS: Rethinking Evaluation Fairness of Weight Sharing Neural Architecture Search | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1907.01845v5) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/fairnas/FairNAS)![Star](https://img.shields.io/github/stars/fairnas/FairNAS.svg?style=social&label=Star) | 2019.07.03 |                 | ICCV 2021    |
| MixNet-L                                     | MixConv: Mixed Depthwise Convolutional Kernels               | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1907.09595v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/%20tensorflow/tpu/tree/master/models/official/mnasnet/mixnet)![Star](https://img.shields.io/github/stars/tensorflow/tpu.svg?style=social&label=Star) | 2019.07.22 |                 |              |
| AOGNet-40M-AN                                | Attentive Normalization                                      | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1908.01259v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/iVMCL/AOGNet-v2)![Star](https://img.shields.io/github/stars/iVMCL/AOGNet-v2.svg?style=social&label=Star) | 2019.08.04 |                 | ECCV 2020    |
| MoGA                                         | MoGA: Searching Beyond MobileNetV3                           | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1908.01314v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/xiaomi-automl/MoGA)![Star](https://img.shields.io/github/stars/xiaomi-automl/MoGA.svg?style=social&label=Star) | 2019.08.04 | xiaomi-automl   |              |
| CSPResNeXt-50 + Mish                         | Mish: A Self Regularized Non-Monotonic Activation Function   | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1908.08681v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/digantamisra98/Mish)![Star](https://img.shields.io/github/stars/digantamisra98/Mish.svg?style=social&label=Star) | 2019.08.23 |                 | BMVC 2020    |
| BBG                                          | Balanced Binary Neural Networks with Gated Residual          | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1909.12117v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/JDAI-CV/dabnn)![Star](https://img.shields.io/github/stars/JDAI-CV/dabnn.svg?style=social&label=Star) | 2019.09.26 |                 |              |
| EfficientNet-B8 (RandAugment)                | RandAugment: Practical automated data augmentation with a reduced search space | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1909.13719v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/rwightman/pytorch-image-models)![Star](https://img.shields.io/github/stars/rwightman/pytorch-image-models.svg?style=social&label=Star) | 2019.09.30 |                 | NeurIPS 2020 |
| ECA-Net<br/>(ResNet-152)                     | ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1910.03151v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/BangguWu/ECANet)![Star](https://img.shields.io/github/stars/BangguWu/ECANet.svg?style=social&label=Star) | 2019.10.08 |                 | CVPR 2020    |
| ResNet-50                                    | On the adequacy of untuned warmup for adaptive optimization  | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1910.04209v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/Tony-Y/pytorch_warmup)![Star](https://img.shields.io/github/stars/Tony-Y/pytorch_warmup.svg?style=social&label=Star) | 2019.10.09 |                 |              |
| SCARLET-A4                                   | SCARLET-NAS: Bridging the Gap between Stability and Scalability in Weight-sharing Neural Architecture Search | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://github.com/xiaomi-automl/SCARLET-NAS) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/xiaomi-automl/ScarletNAS)![Star](https://img.shields.io/github/stars/xiaomi-automl/SCARLET-NAS.svg?style=social&label=Star) | 2019.10.16 |                 |              |
| MobileNet-224<br/>(CGD)                      | Compact Global Descriptor for Neural Networks]               | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1907.09665v10) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/HolmesShuan/Compact-Global-Descriptor)![Star](https://img.shields.io/github/stars/HolmesShuan/Compact-Global-Descriptor.svg?style=social&label=Star) | 2019.10.23 |                 |              |
| HCGNet-C                                     | Gated Convolutional Networks with Hybrid Connectivity for Image Classification | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1908.09699v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/winycg/HCGNet)![Star](https://img.shields.io/github/stars/winycg/HCGNet.svg?style=social&label=Star) | 2019.10.26 |                 |              |
| InceptionV3<br/>(FRN layer)                  | Filter Response Normalization Layer: Eliminating Batch Dependence in the Training of Deep Neural Networks | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1911.09737v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/ensta-u2is/torch-uncertainty)![Star](https://img.shields.io/github/stars/ensta-u2is/torch-uncertainty.svg?style=social&label=Star) | 2019.11.02 |                 | CVPR 2020    |
| NoisyStudent                                 | Self-training with Noisy Student improves ImageNet classification | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1911.04252v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/noisystudent)![Star](https://img.shields.io/github/stars/google-research/noisystudent.svg?style=social&label=Star) | 2019.11.11 |                 | CVPR 2020    |
| AdvProp<br/>(EfficientNet-B8)                | Adversarial Examples Improve Image Recognition               | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1911.09665v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet)![Star](https://img.shields.io/github/stars/tensorflow/tpu.svg?style=social&label=Star) | 2019.11.21 |                 | CVPR 2020    |
| CSPResNeXt-50<br/>(Mish+Aug)                 | CSPNet: A New Backbone that can Enhance Learning Capability of CNN | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1911.11929v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/WongKinYiu/CrossStagePartialNetworks)![Star](https://img.shields.io/github/stars/WongKinYiu/CrossStagePartialNetworks.svg?style=social&label=Star) | 2019.11.27 |                 |              |
| GhostNet                                     | GhostNet: More Features from Cheap Operations                | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1911.11907v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/huawei-noah/ghostnet)![Star](https://img.shields.io/github/stars/huawei-noah/ghostnet.svg?style=social&label=Star) | 2019.11.27 | huawei-noah     | CVPR 2020    |
| Wide ResNet-50<br/>(edge-popup)              | What's Hidden in a Randomly Weighted Neural Network?         | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1911.13299v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/allenai/hidden-networks)![Star](https://img.shields.io/github/stars/allenai/hidden-networks.svg?style=social&label=Star) | 2019.11.29 |                 | CVPR 2020    |
| DY-MobileNetV2 ×1.0                          | Dynamic Convolution: Attention over Convolution Kernels      | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1912.03458v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/kaijieshi/Dynamic-convolution-Pytorch)![Star](https://img.shields.io/github/stars/kaijieshi7/Dynamic-convolution-Pytorch.svg?style=social&label=Star) | 2019.12.07 |                 |              |
| BiT-L                                        | Big Transfer (BiT): General Visual Representation Learning   | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1912.11370v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/big_transfer)![Star](https://img.shields.io/github/stars/google-research/big_transfer.svg?style=social&label=Star) | 2019.12.24 |                 | ECCV 2020    |
| ResNet-200<br/>(Adversarial Autoaugment)     | Adversarial AutoAugment                                      | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/1912.11188v1) | -                                                            | 2019.12.24 |                 | ICLR 2020    |
|                                              |                                                              |                                                              |                                                              |            |                 |              |
| Meta Pseudo Labels<br/>(EfficientNet-L2)     | Meta Pseudo Labels                                           | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2003.10580v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/google-research/tree/master/meta_pseudo_labels)![Star](https://img.shields.io/github/stars/google-research/google-research.svg?style=social&label=Star) | 2020.03.20 |                 | CVPR 2021    |
|                                              |                                                              |                                                              |                                                              |            |                 |              |
| CoAtNet-7                                    | CoAtNet: Marrying Convolution and Attention for All Data Sizes | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2106.04803v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/rwightman/pytorch-image-models)![Star](https://img.shields.io/github/stars/rwightman/pytorch-image-models.svg?style=social&label=Star) | 2021.06.09 |                 | NeurIPS 2021 |
| ViT-G/14                                     | Scaling Vision Transformers                                  | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2106.04560v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/big_vision)![Star](https://img.shields.io/github/stars/google-research/big_vision.svg?style=social&label=Star) | 2021.06.08 |                 | NeurIPS 2021 |
| SwinV2-G                                     | Swin Transformer V2: Scaling Up Capacity and Resolution      | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2111.09883v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/microsoft/Swin-Transformer)![Star](https://img.shields.io/github/stars/microsoft/Swin-Transformer.svg?style=social&label=Star) | 2021.11.18 |                 | CVPR 2022    |
| Florence-CoSwin-H                            | Florence: A New Foundation Model for Computer Vision         | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2111.11432v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/microsoft/unicl)![Star](https://img.shields.io/github/stars/microsoft/unicl.svg?style=social&label=Star) | 2021.11.22 |                 |              |
| NFNet-F4+                                    | High-Performance Large-Scale Image Recognition Without Normalization | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2102.06171v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/deepmind/deepmind-research/tree/master/nfnets)![Star](https://img.shields.io/github/stars/deepmind/deepmind-research.svg?style=social&label=Star) | 2021.02.11 |                 |              |
| TokenLearner L/8                             | TokenLearner: What Can 8 Learned Tokens Do for Images and Videos? | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2106.11297v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/scenic/tree/main/scenic/projects/token_learner)![Star](https://img.shields.io/github/stars/google-research/scenic.svg?style=social&label=Star) | 2021.06.21 |                 |              |
| MViTv2-H                                     | MViTv2: Improved Multiscale Vision Transformers for Classification and Detection | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2112.01526v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/mvit)![Star](https://img.shields.io/github/stars/facebookresearch/mvit.svg?style=social&label=Star) | 2021.12.02 |                 | CVPR 2022    |
| ALIGN                                        | Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2102.05918v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/metaclip)![Star](https://img.shields.io/github/stars/facebookresearch/metaclip.svg?style=social&label=Star) | 2021.02.11 |                 |              |
| BEiT-L                                       | BEiT: BERT Pre-Training of Image Transformers                | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2106.08254v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/microsoft/unilm/tree/master/beit)![Star](https://img.shields.io/github/stars/microsoft/unilm.svg?style=social&label=Star) | 2021.06.15 |                 | ICLR 2020    |
| V-MoE-H/14                                   | Scaling Vision with Sparse Mixture of Experts                | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2106.05974v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/vmoe)![Star](https://img.shields.io/github/stars/google-research/vmoe.svg?style=social&label=Star) | 2021.06.10 | google-research | NeurIPS 2021 |
| PeCo                                         | PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2111.12710v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/xyzforever/bevt)![Star](https://img.shields.io/github/stars/xyzforever/bevt.svg?style=social&label=Star) | 2021.11.24 |                 |              |
| Mixer-H/14<br/>(JFT-300M pre-train)          | MLP-Mixer: An all-MLP Architecture for Vision                | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2105.01601v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/vision_transformer)![Star](https://img.shields.io/github/stars/google-research/vision_transformer.svg?style=social&label=Star) | 2021.05.04 |                 | NeurIPS 2021 |
| MAE<br/>(ViT-H, 448)                         | Masked Autoencoders Are Scalable Vision Learners             | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2111.06377v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/mae)![Star](https://img.shields.io/github/stars/facebookresearch/mae.svg?style=social&label=Star) | 2021.11.11 |                 | CVPR 2022    |
| CvT-W24<br/>(384 res, ImageNet-22k pretrain) | CvT: Introducing Convolutions to Vision Transformers         | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.15808v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/microsoft/CvT)![Star](https://img.shields.io/github/stars/microsoft/CvT.svg?style=social&label=Star) | 2021.03.29 |                 | ICCV 2021    |
| CAIT-XS-36                                   | Going deeper with Image Transformers                         | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.17239v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/rwightman/pytorch-image-models)![Star](https://img.shields.io/github/stars/rwightman/pytorch-image-models.svg?style=social&label=Star) | 2021.03.31 |                 | ICCV 2021    |
| SReT-B<br/>(384 res, ImageNet-1K only)       | Sliced Recursive Transformer                                 | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2111.05297v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/szq0214/sret)![Star](https://img.shields.io/github/stars/szq0214/sret.svg?style=social&label=Star) | 2021.11.09 |                 |              |
| MViT-B-24                                    | Multiscale Vision Transformers                               | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2104.11227v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/SlowFast)![Star](https://img.shields.io/github/stars/facebookresearch/SlowFast.svg?style=social&label=Star) | 2021.04.02 |                 | ICCV 2021    |
| ELSA-VOLO-D1                                 | ELSA: Enhanced Local Self-Attention for Vision Transformer   | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2112.12786v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/damo-cv/elsa)![Star](https://img.shields.io/github/stars/damo-cv/elsa.svg?style=social&label=Star) | 2021.12.23 |                 |              |
| BoTNet T7                                    | Bottleneck Transformers for Visual Recognition               | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2101.11605v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/rwightman/pytorch-image-models)![Star](https://img.shields.io/github/stars/rwightman/pytorch-image-models.svg?style=social&label=Star) | 2021.01.27 |                 | CVPR 2021    |
| SE-CoTNetD-152                               | Contextual Transformer Networks for Visual Recognition       | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2107.12292v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/JDAI-CV/CoTNet)![Star](https://img.shields.io/github/stars/JDAI-CV/CoTNet.svg?style=social&label=Star) | 2021.07.26 |                 |              |
| ResNet-RS-50<br/>(160 image res)             | Revisiting ResNets: Improved Training and Scaling Strategies | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.07579v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/tensorflow/tpu/tree/master/models/official/resnet/resnet_rs)![Star](https://img.shields.io/github/stars/tensorflow/tpu.svg?style=social&label=Star) | 2021.03.13 |                 |              |
| LambdaResNet200                              | LambdaNetworks: Modeling Long-Range Interactions Without Attention | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2102.08602v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/lucidrains/lambda-networks)![Star](https://img.shields.io/github/stars/lucidrains/lambda-networks.svg?style=social&label=Star) | 2021.02.17 |                 |              |
| ViP-B \| 384                                 | Visual Parser: Representing Part-whole Hierarchies with Transformers | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2107.05790v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/kevin-ssy/ViP)![Star](https://img.shields.io/github/stars/kevin-ssy/ViP.svg?style=social&label=Star) | 2021.07.13 |                 |              |
| UniNet-B4                                    | UniNet: Unified Architecture Search with Convolution, Transformer, and MLP | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2110.04035v1) | -                                                            | 2021.10.08 |                 |              |
| FBNetV5-F-CLS                                | FBNetV5: Neural Architecture Search for Multiple Tasks in One Run | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2111.10007v2) | -                                                            | 2021.11.19 |                 |              |
| LV-ViT-M                                     | All Tokens Matter: Token Labeling for Training Better Vision Transformers | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2104.10858v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/zihangJiang/TokenLabeling)![Star](https://img.shields.io/github/stars/zihangJiang/TokenLabeling.svg?style=social&label=Star) | 2021.04.22 |                 |              |
| Conformer-B                                  | Conformer: Local Features Coupling Global Representations for Visual Recognition | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2105.03889v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/pengzhiliang/Conformer)![Star](https://img.shields.io/github/stars/pengzhiliang/Conformer.svg?style=social&label=Star) | 2021.05.09 |                 | ICCV 2021    |
| PatchConvNet-B120                            | Augmenting Convolutional networks with attention-based aggregation | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2112.13692v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/deit)![Star](https://img.shields.io/github/stars/facebookresearch/deit.svg?style=social&label=Star) | 2021.05.09 |                 |              |
| PiT-B                                        | Rethinking Spatial Dimensions of Vision Transformers         | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.16302v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/naver-ai/pit)![Star](https://img.shields.io/github/stars/naver-ai/pit.svg?style=social&label=Star) | 2021.03.30 |                 | ICCV 2021    |
| EfficientNetV2-S                             | EfficientNetV2: Smaller Models and Faster Training           | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2104.00298v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google/automl/tree/master/efficientnetv2)![Star](https://img.shields.io/github/stars/naver-ai/pit.svg?style=social&label=Star) | 2021.03.30 |                 |              |
| DynamicViT-LV-M/0.8                          | DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2106.02034v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/raoyongming/DynamicViT)![Star](https://img.shields.io/github/stars/raoyongming/DynamicViT.svg?style=social&label=Star) | 2021.06.03 |                 | NeurIPS 2021 |
| TNT-B                                        | Transformer in Transformer                                   | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.00112v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/huawei-noah/CV-Backbones/tree/master/tnt_pytorch)![Star](https://img.shields.io/github/stars/huawei-noah/CV-Backbones.svg?style=social&label=Star) | 2021.02.27 |                 | NeurIPS 2021 |
| Transformer local-attention<br/>(NesT-B)     | Nested Hierarchical Transformer: Towards Accurate, Data-Efficient and Interpretable Visual Understanding | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2105.12723v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/nested-transformer)![Star](https://img.shields.io/github/stars/google-research/nested-transformer.svg?style=social&label=Star) | 2021.05.26 |                 |              |
| PVTv2-B4                                     | PVT v2: Improved Baselines with Pyramid Vision Transformer   | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2106.13797v7) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/whai362/PVT)![Star](https://img.shields.io/github/stars/whai362/PVT.svg?style=social&label=Star) | 2021.06.25 |                 |              |
| QnA-ViT-Base                                 | Learned Queries for Efficient Local Attention                | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2112.11435v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/moabarar/qna)![Star](https://img.shields.io/github/stars/moabarar/qna.svg?style=social&label=Star) | 2021.12.21 |                 | CVPR 2022    |
| Twins-SVT-L                                  | Twins: Revisiting the Design of Spatial Attention in Vision Transformers | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2104.13840v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/Meituan-AutoML/Twins)![Star](https://img.shields.io/github/stars/Meituan-AutoML/Twins.svg?style=social&label=Star) | 2021.04.28 |                 | NeurIPS 2021 |
| ViTAE-B-Stage                                | ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2106.03348v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/ViTAE-Transformer/ViTAE-Transformer)![Star](https://img.shields.io/github/stars/ViTAE-Transformer/ViTAE-Transformer.svg?style=social&label=Star) | 2021.06.07 |                 | NeurIPS 2021 |
| ResT-Large                                   | ResT: An Efficient Transformer for Visual Recognition        | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2105.13677v5) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/wofmanaf/ResT)![Star](https://img.shields.io/github/stars/wofmanaf/ResT.svg?style=social&label=Star) | 2021.05.28 |                 | NeurIPS 2021 |
| ResMLP-B24/8                                 | ResMLP: Feedforward networks for image classification with data-efficient training | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2105.03404v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/rwightman/pytorch-image-models)![Star](https://img.shields.io/github/stars/rwightman/pytorch-image-models.svg?style=social&label=Star) | 2021.05.07 |                 | NeurIPS 2021 |
| sMLPNet-B<br/>(ImageNet-1k)                  | Sparse MLP for Image Recognition: Is Self-Attention Really Necessary? | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2109.05422v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/microsoft/SPACH)![Star](https://img.shields.io/github/stars/microsoft/SPACH.svg?style=social&label=Star) | 2021.09.12 |                 |              |
| T2T-ViT-14\|384                              | Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2101.11986v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/yitu-opensource/T2T-ViT)![Star](https://img.shields.io/github/stars/yitu-opensource/T2T-ViT.svg?style=social&label=Star) | 2021.01.28 |                 | ICCV 2021    |
| CeiT-S<br/>(384 finetune res)                | Incorporating Convolution Designs into Visual Transformers   | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.11816v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/rishikksh20/CeiT-pytorch)![Star](https://img.shields.io/github/stars/rishikksh20/CeiT-pytorch.svg?style=social&label=Star) | 2021.03.22 |                 | ICCV 2021    |
| ViL-Medium-D                                 | Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.15358v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/microsoft/vision-longformer)![Star](https://img.shields.io/github/stars/microsoft/vision-longformer.svg?style=social&label=Star) | 2021.03.29 |                 | ICCV 2021    |
| CycleMLP-B5                                  | CycleMLP: A MLP-like Architecture for Dense Prediction       | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2107.10224v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/ShoufaChen/CycleMLP)![Star](https://img.shields.io/github/stars/ShoufaChen/CycleMLP.svg?style=social&label=Star) | 2021.07.21 |                 | ICLR 2022    |
| DeepVit-L*<br/>(DeiT training recipe)        | DeepViT: Towards Deeper Vision Transformer                   | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.11886v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/zhoudaquan/dvit_repo)![Star](https://img.shields.io/github/stars/zhoudaquan/dvit_repo.svg?style=social&label=Star) | 2021.03.22 |                 |              |
|                                              |                                                              |                                                              |                                                              |            |                 |              |
| ZenNAS                                       | Zen-NAS: A Zero-Shot NAS for High-Performance Deep Image Recognition | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2102.01063v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/alibaba/lightweight-neural-architecture-search)![Star](https://img.shields.io/github/stars/alibaba/lightweight-neural-architecture-search.svg?style=social&label=Star) | 2021.02.01 |                 |              |
| NASViT                                       | NASViT: Neural Architecture Search for Efficient Vision Transformers with Gradient Conflict aware Supernet Training | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://openreview.net/forum?id=Qaw16njk6L) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/NASViT)![Star](https://img.shields.io/github/stars/facebookresearch/NASViT.svg?style=social&label=Star) | 2021.02.29 |                 | ICLR 2022    |
| GFNet-H-B                                    | Global Filter Networks for Image Classification              | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2107.00645v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/raoyongming/GFNet)![Star](https://img.shields.io/github/stars/raoyongming/GFNet.svg?style=social&label=Star) | 2021.07.01 |                 | NeurIPS 2021 |
| FunMatch - T384+224<br/>(ResNet-50)          | Knowledge distillation: A good teacher is patient and consistent | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2106.05237v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/big_vision)![Star](https://img.shields.io/github/stars/google-research/big_vision.svg?style=social&label=Star) | 2021.06.09 |                 | CVPR 2022    |
| CrossViT-18+                                 | CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.14899v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/IBM/CrossViT)![Star](https://img.shields.io/github/stars/IBM/CrossViT.svg?style=social&label=Star) | 2021.03.27 |                 | ICCV 2021    |
| HRFormer-B                                   | HRFormer: High-Resolution Transformer for Dense Prediction   | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2110.09408v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/HRNet/HRFormer)![Star](https://img.shields.io/github/stars/HRNet/HRFormer.svg?style=social&label=Star) | 2021.10.18 |                 | ICCV 2021    |
| CCT-14/7x2｜384                              | Escaping the Big Data Paradigm with Compact Transformers     | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2104.05704v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/SHI-Labs/Compact-Transformers)![Star](https://img.shields.io/github/stars/SHI-Labs/Compact-Transformers.svg?style=social&label=Star) | 2021.04.21 |                 |              |
| Container Container                          | Container: Context Aggregation Network                       | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2106.01401v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/allenai/container)![Star](https://img.shields.io/github/stars/allenai/container.svg?style=social&label=Star) | 2021.06.02 |                 |              |
| RVT-B*                                       | Towards Robust Vision Transformer                            | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2105.07926v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/alibaba/easyrobust)![Star](https://img.shields.io/github/stars/alibaba/easyrobust.svg?style=social&label=Star) | 2021.05.17 |                 | CVPR 2022    |
| LeViT-384                                    | LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2104.01136v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/LeViT)![Star](https://img.shields.io/github/stars/facebookresearch/LeViT.svg?style=social&label=Star) | 2021.04.02 |                 | ICCV 2021    |
| MetaFormer PoolFormer-M48                    | MetaFormer Is Actually What You Need for Vision              | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2111.11418v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/sail-sg/poolformer)![Star](https://img.shields.io/github/stars/sail-sg/poolformer.svg?style=social&label=Star) | 2021.11.22 |                 | CVPR 2022    |
| ConViT-B+                                    | ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.10697v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/convit)![Star](https://img.shields.io/github/stars/facebookresearch/convit.svg?style=social&label=Star) | 2021.03.19 |                 |              |
| AutoFormer-base                              | AutoFormer: Searching Transformers for Visual Recognition    | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2107.00651v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/microsoft/AutoML)![Star](https://img.shields.io/github/stars/microsoft/AutoML.svg?style=social&label=Star) | 2021.07.01 |                 | ICCV 2021    |
| ResNet-152 (A2 + reg)                        | ResNet strikes back: An improved training procedure in timm  | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2110.00476v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/rwightman/pytorch-image-models)![Star](https://img.shields.io/github/stars/rwightman/pytorch-image-models.svg?style=social&label=Star) | 2021.10.01 |                 | NeurIPS 2021 |
| DeiT-B with iRPE-K                           | Rethinking and Improving Relative Position Encoding for Vision Transformer | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2107.14222v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/microsoft/Cream/tree/main/iRPE)![Star](https://img.shields.io/github/stars/microsoft/Cream.svg?style=social&label=Star) | 2021.07.29 |                 | ICCV 2021    |
| CAS-ViT-T                                    | CAS-ViT: Convolutional Additive Self-attention Vision Transformers for Efficient Mobile Applications | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2408.03703v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/tianfang-zhang/cas-vit)![Star](https://img.shields.io/github/stars/tianfang-zhang/cas-vit.svg?style=social&label=Star) | 2021.08.07 |                 |              |
| GLiT-Bases                                   | GLiT: Neural Architecture Search for Global and Local Image Transformer | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2107.02960v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/bychen515/glit)![Star](https://img.shields.io/github/stars/bychen515/glit.svg?style=social&label=Star) | 2021.07.07 |                 | ICCV 2021    |
| BossNet-T1                                   | BossNAS: Exploring Hybrid CNN-transformers with Block-wisely Self-supervised Neural Architecture Search | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.12424v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/changlin31/BossNAS)![Star](https://img.shields.io/github/stars/changlin31/BossNAS.svg?style=social&label=Star) | 2021.03.23 |                 | ICCV 2021    |
| Evo-LeViT-384*                               | Evo-ViT: Slow-Fast Token Evolution for Dynamic Vision Transformer | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2108.01390v5) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/YifanXu74/Evo-ViT)![Star](https://img.shields.io/github/stars/YifanXu74/Evo-ViT.svg?style=social&label=Star) | 2021.08.03 |                 |              |
| ConvMixer                                    | Patches Are All You Need?                                    | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2201.09792v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/locuslab/convmixer)![Star](https://img.shields.io/github/stars/locuslab/convmixer.svg?style=social&label=Star) | 2022.01.24 |                 |              |
| DIFFQ                                        | Differentiable Model Compression via Pseudo Quantization Noise | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2104.09987v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/diffq)![Star](https://img.shields.io/github/stars/facebookresearch/diffq.svg?style=social&label=Star) | 2022.04.20 |                 |              |
| Container                                    | Container: Context Aggregation Network                       | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2106.01401v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/allenai/container)![Star](https://img.shields.io/github/stars/allenai/container.svg?style=social&label=Star) | 2021.06.02 |                 |              |
| ResNet-101                                   | A Fast Knowledge Distillation Framework for Visual Recognition | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2112.01528v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/szq0214/fkd)![Star](https://img.shields.io/github/stars/szq0214/fkd.svg?style=social&label=Star) | 2021.12.02 |                 |              |
| ResNet-200                                   | Parametric Contrastive Learning                              | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2107.12028v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/dvlab-research/parametric-contrastive-learning)![Star](https://img.shields.io/github/stars/dvlab-research/parametric-contrastive-learning.svg?style=social&label=Star) | 2021.07.26 |                 | ICCV 2021    |
| RepMLPNet                                    | RepMLPNet: Hierarchical Vision MLP with Re-parameterized Locality | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2112.11081v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/DingXiaoH/RepMLP)![Star](https://img.shields.io/github/stars/DingXiaoH/RepMLP.svg?style=social&label=Star) | 2021.12.21 |                 | CVPR 2022    |
| T2T-ViT-14                                   | Beyond Self-attention: External Attention using Two Linear Layers for Visual Tasks | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2105.02358v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/MenghaoGuo/-EANet)![Star](https://img.shields.io/github/stars/MenghaoGuo/-EANet.svg?style=social&label=Star) | 2021.05.05 |                 |              |
| SE-CoTNetD-50                                | Contextual Transformer Networks for Visual Recognition       | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2107.12292v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/JDAI-CV/CoTNet)![Star](https://img.shields.io/github/stars/JDAI-CV/CoTNet.svg?style=social&label=Star) | 2021.07.26 |                 |              |
| gMLP                                         | Pay Attention to MLPs                                        | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2105.08050v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/labmlai/annotated_deep_learning_paper_implementations)![Star](https://img.shields.io/github/stars/labmlai/annotated_deep_learning_paper_implementations.svg?style=social&label=Star) | 2021.05.17 |                 | NeurIPS 2021 |
| CoE-Large + CondConv                         | Collaboration of Experts: Achieving 80% Top-1 Accuracy on ImageNet with 100M FLOPs | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2107.03815v2) | -                                                            | 2021.07.08 |                 |              |
| Swin                                         | Swin Transformer: Hierarchical Vision Transformer using Shifted Windows | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.14030v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/microsoft/Swin-Transformer)![Star](https://img.shields.io/github/stars/microsoft/Swin-Transformer.svg?style=social&label=Star) | 2021.03.25 |                 | ICCV 2021    |
| ResNet-152x2-SAM                             | When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.14030v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/microsoft/Swin-Transformer)![Star](https://img.shields.io/github/stars/microsoft/Swin-Transformer.svg?style=social&label=Star) | 2021.03.25 |                 |              |
| ResNet-101                                   | Boosting Discriminative Visual Representation Learning with Scenario-Agnostic Mixup | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2111.15454v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/Westlake-AI/openmixup)![Star](https://img.shields.io/github/stars/Westlake-AI/openmixup.svg?style=social&label=Star) | 2021.11.30 |                 |              |
| ResNet-101-mix                               | AutoMix: Unveiling the Power of Mixup for Stronger Classifiers | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.13027v6) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/Westlake-AI/openmixup)![Star](https://img.shields.io/github/stars/Westlake-AI/openmixup.svg?style=social&label=Star) | 2021.03.24 |                 |              |
| CentroidViT-S                                | Centroid Transformers: Learning to Abstract with Attention   | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2102.08606v2) | -                                                            | 2021.02.17 |                 |              |
| AlphaNet-A6                                  | AlphaNet: Improved Training of Supernets with Alpha-Divergence | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2102.07954v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/facebookresearch/AlphaNet)![Star](https://img.shields.io/github/stars/facebookresearch/AlphaNet.svg?style=social&label=Star) | 2021.02.16 |                 |              |
| LocalViT                                     | LocalViT: Bringing Locality to Vision Transformers           | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2104.05707v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/ofsoundof/LocalViT)![Star](https://img.shields.io/github/stars/ofsoundof/LocalViT.svg?style=social&label=Star) | 2021.04.12 |                 |              |
| DAFT-conv                                    | A Dot Product Attention Free Transformer                     | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://openreview.net/forum?id=JVR4JswsEM) | -                                                            | 2021.09.29 |                 |              |
| DVT                                          | Not All Images are Worth 16x16 Words: Dynamic Transformers for Efficient Image Recognition | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2105.15075v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/blackfeather-wang/Dynamic-Vision-Transformer)![Star](https://img.shields.io/github/stars/blackfeather-wang/Dynamic-Vision-Transformer.svg?style=social&label=Star) | 2021.04.12 |                 | NeurIPS 2021 |
| ResNet-50+AutoDropout+RandAugment            | AutoDropout: Learning Dropout Patterns to Regularize Deep Networks | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2101.01761v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/google-research/google-research)![Star](https://img.shields.io/github/stars/google-research/google-research.svg?style=social&label=Star) | 2021.01.05 |                 |              |
| ConvMLP                                      | ConvMLP: Hierarchical Convolutional MLPs for Vision          | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2109.04454v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/SHI-Labs/Convolutional-MLPs)![Star](https://img.shields.io/github/stars/SHI-Labs/Convolutional-MLPs.svg?style=social&label=Star) | 2021.09.09 |                 |              |
| WideNet-H                                    | Go Wider Instead of Deeper                                   | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2107.11817v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/XueFuzhao/WideNet_Code)![Star](https://img.shields.io/github/stars/XueFuzhao/WideNet_Code.svg?style=social&label=Star) | 2021.07.25 |                 |              |
| BasisNet                                     | BasisNet: Two-stage Model Synthesis for Efficient Inference  | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2105.03014v1) |                                                              | 2021.05.07 |                 |              |
| RedNet-152                                   | Involution: Inverting the Inherence of Convolution for Visual Recognition | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.06255v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/d-li14/involution)![Star](https://img.shields.io/github/stars/d-li14/involution.svg?style=social&label=Star) | 2021.03.10 |                 | CVPR 2021    |
| Co-ResNet-152                                | Contextual Convolutional Neural Networks                     | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2108.07387v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/iduta/coconv)![Star](https://img.shields.io/github/stars/iduta/coconv.svg?style=social&label=Star) | 2021.08.17 |                 |              |
| RepVGG                                       | RepVGG: Making VGG-style ConvNets Great Again                | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2101.03697v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/megvii-model/RepVGG)![Star](https://img.shields.io/github/stars/megvii-model/RepVGG.svg?style=social&label=Star) | 2021.01.11 |                 | CVPR 2021    |
| Visformer-Ti                                 | Visformer: The Vision-friendly Transformer                   | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2104.12533v4) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/danczs/Visformer)![Star](https://img.shields.io/github/stars/danczs/Visformer.svg?style=social&label=Star) | 2021.04.26 |                 | ICCV 2021    |
| RepMLP                                       | RepMLP: Re-parameterizing Convolutions into Fully-connected Layers for Image Recognition | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2105.01883v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/DingXiaoH/RepMLP)![Star](https://img.shields.io/github/stars/DingXiaoH/RepMLP.svg?style=social&label=Star) | 2021.05.05 |                 |              |
| ReXNet_1.0-relabel                           | Re-labeling ImageNet: from Single to Multi-Labels, from Global to Localized Labels | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2101.05022v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/naver-ai/relabel_imagenet)![Star](https://img.shields.io/github/stars/naver-ai/relabel_imagenet.svg?style=social&label=Star) | 2021.01.13 |                 | CVPR 2021    |
| MobileViT                                    | MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2110.02178v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)]( https://github.com/apple/ml-cvnets)![Star](https://img.shields.io/github/stars/apple/ml-cvnets.svg?style=social&label=Star) | 2021.01.13 | Apple           | ICLR 2022    |
| HVT-S-1                                      | Scalable Vision Transformers with Hierarchical Pooling       | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.10619v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/MonashAI/HVT)![Star](https://img.shields.io/github/stars/MonashAI/HVT.svg?style=social&label=Star) | 2021.03.19 |                 | ICCV 2021    |
| Perceiver                                    | Perceiver: General Perception with Iterative Attention       | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2103.03206v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/lucidrains/perceiver-pytorch)![Star](https://img.shields.io/github/stars/lucidrains/perceiver-pytorch.svg?style=social&label=Star) | 2021.03.04 |                 |              |
| SkipblockNet                                 | Bias Loss for Mobile Neural Networks                         | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2107.11170v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/lusinlu/biasloss_skipblocknet)![Star](https://img.shields.io/github/stars/lusinlu/biasloss_skipblocknet.svg?style=social&label=Star) | 2021.07.23 |                 | ICCV 2021    |
| SSAL-Resnet50                                | Contextual Classification Using Self-Supervised Auxiliary Models for Deep Neural Networks | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2101.03057v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/Engler93/Self-Supervised-Autogenous-Learning)![Star](https://img.shields.io/github/stars/Engler93/Self-Supervised-Autogenous-Learning.svg?style=social&label=Star) | 2021.01.07 |                 |              |
| X-volution                                   | X-volution: On the unification of convolution and self-attention | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2106.02253v2) | -                                                            | 2021.06.04 |                 |              |
| ResNet-50 MLPerf v0.7 - 2512 steps           | A Large Batch Optimizer Reality Check: Traditional, Generic Optimizers Suffice Across Batch Sizes | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2102.06356v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/Engler93/Self-Supervised-Autogenous-Learning)![Star](https://img.shields.io/github/stars/Engler93/Self-Supervised-Autogenous-Learning.svg?style=social&label=Star) | 2021.02.12 |                 | NeurIPS 2021 |
| FF                                           | Do You Even Need Attention? A Stack of Feed-Forward Layers Does Surprisingly Well on ImageNet | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2105.02723v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/lukemelas/do-you-even-need-attention)![Star](https://img.shields.io/github/stars/lukemelas/do-you-even-need-attention.svg?style=social&label=Star) | 2021.05.06 |                 |              |
| PDC                                          | Augmenting Deep Classifiers with Polynomial Neural Networks  | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2104.07916v2) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/grigorisg9gr/polynomials-for-augmenting-NNs)![Star](https://img.shields.io/github/stars/grigorisg9gr/polynomials-for-augmenting-NNs.svg?style=social&label=Star) | 2021.04.06 |                 |              |
| AsymmNet                                     | AsymmNet: Towards ultralight convolution neural networks using asymmetrical bottlenecks | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2104.07770v1) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/Spark001/AsymmNet)![Star](https://img.shields.io/github/stars/Spark001/AsymmNet.svg?style=social&label=Star) | 2021.04.15 |                 |              |
|                                              |                                                              |                                                              |                                                              |            |                 |              |
| CoCa                                         | CoCa: Contrastive Captioners are Image-Text Foundation Models | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/pdf/2205.01917v2.pdf) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/mlfoundations/open_clip)![Star](https://img.shields.io/github/stars/mlfoundations/open_clip.svg?style=social&label=Star) | 2022.05.04 |                 |              |
| Model soups                                  | Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2203.05482v3) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/mlfoundations/model-soups)![Star](https://img.shields.io/github/stars/mlfoundations/model-soups.svg?style=social&label=Star) | 2022.05.04 |                 |              |
|                                              |                                                              |                                                              |                                                              |            |                 |              |
|                                              |                                                              |                                                              |                                                              |            |                 |              |
|                                              |                                                              |                                                              |                                                              |            |                 |              |
|                                              |                                                              |                                                              |                                                              |            |                 |              |
|                                              |                                                              |                                                              |                                                              |            |                 |              |
|                                              |                                                              |                                                              |                                                              |            |                 |              |
|                                              |                                                              |                                                              |                                                              |            |                 |              |
|                                              |                                                              |                                                              |                                                              |            |                 |              |

## Efficient ViTs on ImageNet-1K (with DeiT-T)

- https://paperswithcode.com/sota/efficient-vits-on-imagenet-1k-with-deit-t

| Model / Methods | Title | Paper Link                                                   | Code Link                                                    | Published | Keywords | Venue |
| --------------- | ----- | ------------------------------------------------------------ | ------------------------------------------------------------ | --------- | -------- | ----- |
|                 |       | [![Paper](https://img.shields.io/badge/Paper-cyd7e6?style=for-the-badge)](https://arxiv.org/abs/2108.01390v5) | [![Code](https://img.shields.io/badge/Code-add7e6?style=for-the-badge)](https://github.com/changlin31/BossNAS)![Star](https://img.shields.io/github/stars/changlin31/BossNAS.svg?style=social&label=Star) |           |          |       |
|                 |       |                                                              |                                                              |           |          |       |

